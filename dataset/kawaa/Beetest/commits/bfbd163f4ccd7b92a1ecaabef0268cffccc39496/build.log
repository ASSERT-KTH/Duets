[INFO] Error stacktraces are turned on.
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for com.spotify:Beetest:jar:1.0-SNAPSHOT
[WARNING] 'dependencies.dependency.(groupId:artifactId:type:classifier)' must be unique: org.apache.hadoop:hadoop-client:jar -> duplicate declaration of version ${hadoop.version} @ line 68, column 17
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
[INFO] 
[INFO] ------------------------< com.spotify:Beetest >-------------------------
[INFO] Building Beetest 1.0-SNAPSHOT
[INFO] --------------------------------[ jar ]---------------------------------
[WARNING] The POM for org.apache.hadoop:hadoop-common:jar:0.22.0-SNAPSHOT is missing, no dependency information available
[INFO] 
[INFO] --- jacoco-maven-plugin:0.8.5:prepare-agent (default) @ Beetest ---
[INFO] argLine set to -javaagent:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar=destfile=/tmp/tmpu74hqnl2/Beetest/target/jacoco.exec
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ Beetest ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 10 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ Beetest ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 4 source files to /tmp/tmpu74hqnl2/Beetest/target/classes
[WARNING] /tmp/tmpu74hqnl2/Beetest/src/main/java/com/spotify/beetest/MiniCluster.java: /tmp/tmpu74hqnl2/Beetest/src/main/java/com/spotify/beetest/MiniCluster.java uses or overrides a deprecated API.
[WARNING] /tmp/tmpu74hqnl2/Beetest/src/main/java/com/spotify/beetest/MiniCluster.java: Recompile with -Xlint:deprecation for details.
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ Beetest ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 7 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ Beetest ---
[INFO] Changes detected - recompiling the module!
[INFO] Compiling 5 source files to /tmp/tmpu74hqnl2/Beetest/target/test-classes
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ Beetest ---
[INFO] Surefire report directory: /tmp/tmpu74hqnl2/Beetest/target/surefire-reports

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running com.spotify.beetest.QueryGeneratorTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.036 sec - in com.spotify.beetest.QueryGeneratorTest
Running com.spotify.beetest.TestMiniCluster
Jul 30, 2020 9:42:13 PM com.spotify.beetest.TestMiniCluster setUp
INFO: STARTING CLUSTER at: /tmp/MiniClusterTest-239445528
20/07/30 21:42:14 INFO Configuration.deprecation: mapred.max.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.maxsize
20/07/30 21:42:14 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/07/30 21:42:14 INFO Configuration.deprecation: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
20/07/30 21:42:14 INFO Configuration.deprecation: mapred.min.split.size.per.rack is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.rack
20/07/30 21:42:14 INFO Configuration.deprecation: mapred.min.split.size is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize
20/07/30 21:42:14 INFO Configuration.deprecation: mapred.min.split.size.per.node is deprecated. Instead, use mapreduce.input.fileinputformat.split.minsize.per.node
20/07/30 21:42:14 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
20/07/30 21:42:14 INFO Configuration.deprecation: mapred.input.dir.recursive is deprecated. Instead, use mapreduce.input.fileinputformat.input.dir.recursive
20/07/30 21:42:14 WARN conf.HiveConf: HiveConf of name hive.root.logger does not exist
20/07/30 21:42:14 INFO hdfs.MiniDFSCluster: starting cluster with 1 namenodes.
20/07/30 21:42:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Formatting using clusterid: testClusterID
20/07/30 21:42:14 INFO namenode.HostFileManager: read includes:
HostSet(
)
20/07/30 21:42:14 INFO namenode.HostFileManager: read excludes:
HostSet(
)
20/07/30 21:42:14 INFO Configuration.deprecation: hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
20/07/30 21:42:14 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/07/30 21:42:14 INFO util.GSet: Computing capacity for map BlocksMap
20/07/30 21:42:14 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:14 INFO util.GSet: 2.0% max memory = 1.1 GB
20/07/30 21:42:14 INFO util.GSet: capacity      = 2^22 = 4194304 entries
20/07/30 21:42:14 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/07/30 21:42:14 INFO blockmanagement.BlockManager: defaultReplication         = 1
20/07/30 21:42:14 INFO blockmanagement.BlockManager: maxReplication             = 512
20/07/30 21:42:14 INFO blockmanagement.BlockManager: minReplication             = 1
20/07/30 21:42:14 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/07/30 21:42:14 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/07/30 21:42:14 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/07/30 21:42:14 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/07/30 21:42:14 INFO namenode.FSNamesystem: fsOwner             = jdbl (auth:SIMPLE)
20/07/30 21:42:14 INFO namenode.FSNamesystem: supergroup          = supergroup
20/07/30 21:42:14 INFO namenode.FSNamesystem: isPermissionEnabled = false
20/07/30 21:42:14 INFO namenode.FSNamesystem: HA Enabled: false
20/07/30 21:42:14 INFO namenode.FSNamesystem: Append Enabled: true
20/07/30 21:42:14 INFO util.GSet: Computing capacity for map INodeMap
20/07/30 21:42:14 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:14 INFO util.GSet: 1.0% max memory = 1.1 GB
20/07/30 21:42:14 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/07/30 21:42:14 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/07/30 21:42:14 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/07/30 21:42:14 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/07/30 21:42:14 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
20/07/30 21:42:14 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/07/30 21:42:14 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/07/30 21:42:14 INFO util.GSet: Computing capacity for map Namenode Retry Cache
20/07/30 21:42:14 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:14 INFO util.GSet: 0.029999999329447746% max memory = 1.1 GB
20/07/30 21:42:14 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/07/30 21:42:14 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/name1 has been successfully formatted.
20/07/30 21:42:14 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/name2 has been successfully formatted.
20/07/30 21:42:14 INFO namenode.FSImage: Saving image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage.ckpt_0000000000000000000 using no compression
20/07/30 21:42:14 INFO namenode.FSImage: Saving image file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/fsimage.ckpt_0000000000000000000 using no compression
20/07/30 21:42:14 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/fsimage.ckpt_0000000000000000000 of size 196 bytes saved in 0 seconds.
20/07/30 21:42:14 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage.ckpt_0000000000000000000 of size 196 bytes saved in 0 seconds.
20/07/30 21:42:14 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
20/07/30 21:42:14 WARN impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
20/07/30 21:42:14 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
20/07/30 21:42:14 INFO impl.MetricsSystemImpl: NameNode metrics system started
20/07/30 21:42:14 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
20/07/30 21:42:15 INFO http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
20/07/30 21:42:15 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
20/07/30 21:42:15 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20/07/30 21:42:15 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
20/07/30 21:42:15 INFO http.HttpServer: dfs.webhdfs.enabled = false
20/07/30 21:42:15 INFO http.HttpServer: Jetty bound to port 34781
20/07/30 21:42:15 INFO mortbay.log: jetty-6.1.26
20/07/30 21:42:15 INFO mortbay.log: Extract jar:file:/home/jdbl/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_34781_hdfs____749xjt/webapp
20/07/30 21:42:15 INFO mortbay.log: Started SelectChannelConnector@localhost:34781
20/07/30 21:42:15 INFO namenode.NameNode: Web-server up at: localhost:34781
20/07/30 21:42:15 INFO namenode.HostFileManager: read includes:
HostSet(
)
20/07/30 21:42:15 INFO namenode.HostFileManager: read excludes:
HostSet(
)
20/07/30 21:42:15 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/07/30 21:42:15 INFO util.GSet: Computing capacity for map BlocksMap
20/07/30 21:42:15 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:15 INFO util.GSet: 2.0% max memory = 1.1 GB
20/07/30 21:42:15 INFO util.GSet: capacity      = 2^22 = 4194304 entries
20/07/30 21:42:15 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/07/30 21:42:15 INFO blockmanagement.BlockManager: defaultReplication         = 1
20/07/30 21:42:15 INFO blockmanagement.BlockManager: maxReplication             = 512
20/07/30 21:42:15 INFO blockmanagement.BlockManager: minReplication             = 1
20/07/30 21:42:15 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/07/30 21:42:15 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/07/30 21:42:15 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/07/30 21:42:15 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/07/30 21:42:15 INFO namenode.FSNamesystem: fsOwner             = jdbl (auth:SIMPLE)
20/07/30 21:42:15 INFO namenode.FSNamesystem: supergroup          = supergroup
20/07/30 21:42:15 INFO namenode.FSNamesystem: isPermissionEnabled = false
20/07/30 21:42:15 INFO namenode.FSNamesystem: HA Enabled: false
20/07/30 21:42:15 INFO namenode.FSNamesystem: Append Enabled: true
20/07/30 21:42:15 INFO util.GSet: Computing capacity for map INodeMap
20/07/30 21:42:15 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:15 INFO util.GSet: 1.0% max memory = 1.1 GB
20/07/30 21:42:15 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/07/30 21:42:15 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/07/30 21:42:15 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/07/30 21:42:15 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/07/30 21:42:15 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
20/07/30 21:42:15 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/07/30 21:42:15 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/07/30 21:42:15 INFO util.GSet: Computing capacity for map Namenode Retry Cache
20/07/30 21:42:15 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:15 INFO util.GSet: 0.029999999329447746% max memory = 1.1 GB
20/07/30 21:42:15 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/07/30 21:42:15 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/name1/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:15 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/name2/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:15 INFO namenode.FileJournalManager: Recovering unfinalized segments in /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current
20/07/30 21:42:15 INFO namenode.FileJournalManager: Recovering unfinalized segments in /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current
20/07/30 21:42:15 INFO namenode.FSImage: No edit log streams selected.
20/07/30 21:42:15 INFO namenode.FSImage: Loading image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000 using no compression
20/07/30 21:42:15 INFO namenode.FSImage: Number of files = 1
20/07/30 21:42:15 INFO namenode.FSImage: Number of files under construction = 0
20/07/30 21:42:15 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000 of size 196 bytes loaded in 0 seconds.
20/07/30 21:42:15 INFO namenode.FSImage: Loaded image for txid 0 from /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000
20/07/30 21:42:15 INFO namenode.FSEditLog: Starting log segment at 1
20/07/30 21:42:15 INFO namenode.NameCache: initialized with 0 entries 0 lookups
20/07/30 21:42:15 INFO namenode.FSNamesystem: Finished loading FSImage in 307 msecs
20/07/30 21:42:15 INFO namenode.NameNode: RPC server is binding to localhost:0
20/07/30 21:42:15 INFO ipc.Server: Starting Socket Reader #1 for port 38933
20/07/30 21:42:15 INFO namenode.FSNamesystem: Registered FSNamesystemState MBean
20/07/30 21:42:15 INFO namenode.FSNamesystem: Number of blocks under construction: 0
20/07/30 21:42:15 INFO namenode.FSNamesystem: Number of blocks under construction: 0
20/07/30 21:42:15 INFO namenode.FSNamesystem: initializing replication queues
20/07/30 21:42:15 INFO blockmanagement.BlockManager: Total number of blocks            = 0
20/07/30 21:42:15 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0
20/07/30 21:42:15 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0
20/07/30 21:42:15 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0
20/07/30 21:42:15 INFO blockmanagement.BlockManager: Number of blocks being written    = 0
20/07/30 21:42:15 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
20/07/30 21:42:15 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs
20/07/30 21:42:15 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
20/07/30 21:42:15 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
20/07/30 21:42:15 INFO ipc.Server: IPC Server Responder: starting
20/07/30 21:42:15 INFO ipc.Server: IPC Server listener on 38933: starting
20/07/30 21:42:15 INFO namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:38933
20/07/30 21:42:15 INFO namenode.FSNamesystem: Starting services required for active state
20/07/30 21:42:15 INFO hdfs.MiniDFSCluster: Starting DataNode 0 with dfs.datanode.data.dir: file:/tmp/MiniClusterTest-239445528/BeetestCluster/data/data1,file:/tmp/MiniClusterTest-239445528/BeetestCluster/data/data2
20/07/30 21:42:15 INFO impl.MetricsSystemImpl: DataNode metrics system started (again)
20/07/30 21:42:15 INFO datanode.DataNode: Configured hostname is 127.0.0.1
20/07/30 21:42:15 INFO datanode.DataNode: Opened streaming server at /127.0.0.1:40369
20/07/30 21:42:16 INFO datanode.DataNode: Balancing bandwith is 1048576 bytes/s
20/07/30 21:42:16 INFO http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
20/07/30 21:42:16 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
20/07/30 21:42:16 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20/07/30 21:42:16 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
20/07/30 21:42:16 INFO datanode.DataNode: Opened info server at localhost:0
20/07/30 21:42:16 INFO datanode.DataNode: dfs.webhdfs.enabled = false
20/07/30 21:42:16 INFO http.HttpServer: Jetty bound to port 43845
20/07/30 21:42:16 INFO mortbay.log: jetty-6.1.26
20/07/30 21:42:16 INFO mortbay.log: Extract jar:file:/home/jdbl/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_43845_datanode____.ci0wfz/webapp
20/07/30 21:42:16 INFO mortbay.log: Started SelectChannelConnector@localhost:43845
20/07/30 21:42:16 INFO ipc.Server: Starting Socket Reader #1 for port 36697
20/07/30 21:42:16 INFO datanode.DataNode: Opened IPC server at /127.0.0.1:36697
20/07/30 21:42:16 INFO datanode.DataNode: Refresh request received for nameservices: null
20/07/30 21:42:16 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>
20/07/30 21:42:16 INFO datanode.DataNode: Block pool <registering> (storage id unknown) service to localhost/127.0.0.1:38933 starting to offer service
20/07/30 21:42:16 INFO ipc.Server: IPC Server Responder: starting
20/07/30 21:42:16 INFO ipc.Server: IPC Server listener on 36697: starting
20/07/30 21:42:16 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:16 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1 is not formatted
20/07/30 21:42:16 INFO common.Storage: Formatting ...
20/07/30 21:42:16 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:16 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2 is not formatted
20/07/30 21:42:16 INFO common.Storage: Formatting ...
20/07/30 21:42:16 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:42:16 INFO common.Storage: Locking is disabled
20/07/30 21:42:16 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current/BP-540639934-172.17.0.16-1596145334622 is not formatted.
20/07/30 21:42:16 INFO common.Storage: Formatting ...
20/07/30 21:42:16 INFO common.Storage: Formatting block pool BP-540639934-172.17.0.16-1596145334622 directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current/BP-540639934-172.17.0.16-1596145334622/current
20/07/30 21:42:16 INFO common.Storage: Locking is disabled
20/07/30 21:42:16 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current/BP-540639934-172.17.0.16-1596145334622 is not formatted.
20/07/30 21:42:16 INFO common.Storage: Formatting ...
20/07/30 21:42:16 INFO common.Storage: Formatting block pool BP-540639934-172.17.0.16-1596145334622 directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current/BP-540639934-172.17.0.16-1596145334622/current
20/07/30 21:42:16 INFO datanode.DataNode: Setting up storage: nsid=1901640855;bpid=BP-540639934-172.17.0.16-1596145334622;lv=-47;nsInfo=lv=-47;cid=testClusterID;nsid=1901640855;c=0;bpid=BP-540639934-172.17.0.16-1596145334622
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Added volume - /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Added volume - /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean
20/07/30 21:42:16 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:42:16 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1596158841824 with interval 21600000
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Adding block pool BP-540639934-172.17.0.16-1596145334622
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Scanning block pool BP-540639934-172.17.0.16-1596145334622 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current...
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Scanning block pool BP-540639934-172.17.0.16-1596145334622 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current...
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-540639934-172.17.0.16-1596145334622 on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current: 10ms
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-540639934-172.17.0.16-1596145334622 on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current: 7ms
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-540639934-172.17.0.16-1596145334622: 12ms
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-540639934-172.17.0.16-1596145334622 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current...
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-540639934-172.17.0.16-1596145334622 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current: 0ms
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-540639934-172.17.0.16-1596145334622 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current...
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-540639934-172.17.0.16-1596145334622 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current: 0ms
20/07/30 21:42:16 INFO impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
20/07/30 21:42:16 INFO datanode.DataNode: Block pool BP-540639934-172.17.0.16-1596145334622 (storage id DS-1189148701-172.17.0.16-40369-1596145336625) service to localhost/127.0.0.1:38933 beginning handshake with NN
20/07/30 21:42:16 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1189148701-172.17.0.16-40369-1596145336625, infoPort=43845, ipcPort=36697, storageInfo=lv=-47;cid=testClusterID;nsid=1901640855;c=0) storage DS-1189148701-172.17.0.16-40369-1596145336625
20/07/30 21:42:16 INFO net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:40369
20/07/30 21:42:16 INFO datanode.DataNode: Block pool Block pool BP-540639934-172.17.0.16-1596145334622 (storage id DS-1189148701-172.17.0.16-40369-1596145336625) service to localhost/127.0.0.1:38933 successfully registered with NN
20/07/30 21:42:16 INFO datanode.DataNode: For namenode localhost/127.0.0.1:38933 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec Initial delay: 0msec; heartBeatInterval=3000
20/07/30 21:42:16 INFO datanode.DataNode: Namenode Block pool BP-540639934-172.17.0.16-1596145334622 (storage id DS-1189148701-172.17.0.16-40369-1596145336625) service to localhost/127.0.0.1:38933 trying to claim ACTIVE state with txid=1
20/07/30 21:42:16 INFO datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-540639934-172.17.0.16-1596145334622 (storage id DS-1189148701-172.17.0.16-40369-1596145336625) service to localhost/127.0.0.1:38933
20/07/30 21:42:16 INFO hdfs.MiniDFSCluster: Cluster is active
20/07/30 21:42:16 INFO blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:40369 after starting up or becoming active. Its block contents are no longer considered stale
20/07/30 21:42:16 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1189148701-172.17.0.16-40369-1596145336625, infoPort=43845, ipcPort=36697, storageInfo=lv=-47;cid=testClusterID;nsid=1901640855;c=0), blocks: 0, processing time: 2 msecs
20/07/30 21:42:16 INFO datanode.DataNode: BlockReport of 0 blocks took 1 msec to generate and 54 msecs for RPC and NN processing
20/07/30 21:42:16 INFO datanode.DataNode: sent block report, processed command:org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@599682c2
20/07/30 21:42:16 INFO util.GSet: Computing capacity for map BlockMap
20/07/30 21:42:16 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:16 INFO util.GSet: 0.5% max memory = 1.1 GB
20/07/30 21:42:16 INFO util.GSet: capacity      = 2^20 = 1048576 entries
20/07/30 21:42:16 INFO datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-540639934-172.17.0.16-1596145334622
20/07/30 21:42:16 INFO datanode.DataBlockScanner: Added bpid=BP-540639934-172.17.0.16-1596145334622 to blockPoolScannerMap, new size=1
20/07/30 21:42:17 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
20/07/30 21:42:17 INFO metastore.ObjectStore: ObjectStore, initialize called
20/07/30 21:42:17 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
20/07/30 21:42:17 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
20/07/30 21:42:22 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
20/07/30 21:42:24 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:42:24 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:42:26 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:42:26 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:42:27 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/07/30 21:42:27 INFO metastore.ObjectStore: Initialized ObjectStore
20/07/30 21:42:27 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
20/07/30 21:42:27 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
20/07/30 21:42:28 INFO metastore.HiveMetaStore: Added admin role in metastore
20/07/30 21:42:28 INFO metastore.HiveMetaStore: Added public role in metastore
20/07/30 21:42:28 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
20/07/30 21:42:28 INFO metastore.HiveMetaStore: 0: get_all_databases
20/07/30 21:42:28 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_all_databases	
20/07/30 21:42:28 INFO metastore.HiveMetaStore: 0: get_functions: db=default pat=*
20/07/30 21:42:28 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
20/07/30 21:42:28 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:42:28 INFO session.SessionState: Created HDFS directory: hdfs://localhost:38933/tmp/beetest/scratchdir/jdbl
20/07/30 21:42:28 INFO session.SessionState: Created local directory: /tmp/MiniClusterTest-239445528/localScratchDir
20/07/30 21:42:28 INFO session.SessionState: Created local directory: /tmp/104c71fc-4d44-4661-b50c-873e7c2a6eaf_resources
20/07/30 21:42:28 INFO session.SessionState: Created HDFS directory: hdfs://localhost:38933/tmp/beetest/scratchdir/jdbl/104c71fc-4d44-4661-b50c-873e7c2a6eaf
20/07/30 21:42:29 INFO session.SessionState: Created local directory: /tmp/MiniClusterTest-239445528/localScratchDir/104c71fc-4d44-4661-b50c-873e7c2a6eaf
20/07/30 21:42:29 INFO session.SessionState: Created HDFS directory: hdfs://localhost:38933/tmp/beetest/scratchdir/jdbl/104c71fc-4d44-4661-b50c-873e7c2a6eaf/_tmp_space.db
20/07/30 21:42:29 INFO service.CompositeService: Operation log root directory is created: /tmp/jdbl/operation_logs
20/07/30 21:42:29 INFO service.CompositeService: HiveServer2: Background operation thread pool size: 100
20/07/30 21:42:29 INFO service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
20/07/30 21:42:29 INFO service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
20/07/30 21:42:29 INFO service.AbstractService: Service:OperationManager is inited.
20/07/30 21:42:29 INFO service.AbstractService: Service:SessionManager is inited.
20/07/30 21:42:29 INFO service.AbstractService: Service:CLIService is inited.
20/07/30 21:42:29 INFO service.AbstractService: Service:ThriftBinaryCLIService is inited.
20/07/30 21:42:29 INFO service.AbstractService: Service:HiveServer2 is inited.
20/07/30 21:42:29 INFO service.AbstractService: Service:OperationManager is started.
20/07/30 21:42:29 INFO service.AbstractService: Service:SessionManager is started.
20/07/30 21:42:29 INFO service.AbstractService: Service:CLIService is started.
20/07/30 21:42:29 INFO metastore.ObjectStore: ObjectStore, initialize called
20/07/30 21:42:29 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
20/07/30 21:42:29 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/07/30 21:42:29 INFO metastore.ObjectStore: Initialized ObjectStore
20/07/30 21:42:29 INFO metastore.HiveMetaStore: 0: get_databases: default
20/07/30 21:42:29 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_databases: default	
20/07/30 21:42:29 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
20/07/30 21:42:29 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Shutting down the object store...	
20/07/30 21:42:29 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
20/07/30 21:42:29 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
20/07/30 21:42:29 INFO service.AbstractService: Service:ThriftBinaryCLIService is started.
20/07/30 21:42:29 INFO service.AbstractService: Service:HiveServer2 is started.
20/07/30 21:42:29 INFO Configuration.deprecation: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
20/07/30 21:42:29 INFO Configuration.deprecation: dfs.safemode.extension is deprecated. Instead, use dfs.namenode.safemode.extension
20/07/30 21:42:29 INFO Configuration.deprecation: dfs.http.address is deprecated. Instead, use dfs.namenode.http-address
20/07/30 21:42:29 INFO Configuration.deprecation: slave.host.name is deprecated. Instead, use dfs.datanode.hostname
20/07/30 21:42:29 INFO Configuration.deprecation: dfs.umaskmode is deprecated. Instead, use fs.permissions.umask-mode
20/07/30 21:42:29 INFO Configuration.deprecation: dfs.permissions is deprecated. Instead, use dfs.permissions.enabled
20/07/30 21:42:29 INFO Configuration.deprecation: dfs.name.dir is deprecated. Instead, use dfs.namenode.name.dir
20/07/30 21:42:29 INFO Configuration.deprecation: dfs.data.dir is deprecated. Instead, use dfs.datanode.data.dir
20/07/30 21:42:29 INFO Configuration.deprecation: fs.checkpoint.dir is deprecated. Instead, use dfs.namenode.checkpoint.dir
20/07/30 21:42:29 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
20/07/30 21:42:29 INFO thrift.ThriftCLIService: Starting ThriftBinaryCLIService on port 45905 with 5...500 worker threads
Jul 30, 2020 9:42:29 PM com.spotify.beetest.TestMiniCluster testClusterConfiguration
INFO: TESTING CONFIGURATION
20/07/30 21:42:29 WARN conf.Configuration: /tmp/MiniClusterTest-239445528/MiniDFSClusterConfig/local-config:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
20/07/30 21:42:29 WARN conf.Configuration: /tmp/MiniClusterTest-239445528/MiniDFSClusterConfig/local-config:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
Jul 30, 2020 9:42:29 PM com.spotify.beetest.TestMiniCluster tearDown
INFO: STOPPING CLUSTER
20/07/30 21:42:29 INFO hdfs.MiniDFSCluster: Shutting down the Mini HDFS Cluster
20/07/30 21:42:29 INFO hdfs.MiniDFSCluster: Shutting down DataNode 0
20/07/30 21:42:29 WARN datanode.DirectoryScanner: DirectoryScanner: shutdown has been called
20/07/30 21:42:29 INFO mortbay.log: Stopped SelectChannelConnector@localhost:0
20/07/30 21:42:29 INFO ipc.Server: Stopping server on 36697
20/07/30 21:42:29 INFO ipc.Server: Stopping IPC Server listener on 36697
20/07/30 21:42:29 INFO datanode.DataNode: Waiting for threadgroup to exit, active threads is 1
20/07/30 21:42:29 INFO ipc.Server: Stopping IPC Server Responder
20/07/30 21:42:29 INFO datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
20/07/30 21:42:29 WARN datanode.DataNode: BPOfferService for Block pool BP-540639934-172.17.0.16-1596145334622 (storage id DS-1189148701-172.17.0.16-40369-1596145336625) service to localhost/127.0.0.1:38933 interrupted
20/07/30 21:42:29 WARN datanode.DataNode: Ending block pool service for: Block pool BP-540639934-172.17.0.16-1596145334622 (storage id DS-1189148701-172.17.0.16-40369-1596145336625) service to localhost/127.0.0.1:38933
20/07/30 21:42:29 INFO datanode.DataNode: Removed Block pool BP-540639934-172.17.0.16-1596145334622 (storage id DS-1189148701-172.17.0.16-40369-1596145336625)
20/07/30 21:42:29 INFO datanode.DataBlockScanner: Removed bpid=BP-540639934-172.17.0.16-1596145334622 from blockPoolScannerMap
20/07/30 21:42:29 INFO impl.FsDatasetImpl: Removing block pool BP-540639934-172.17.0.16-1596145334622
20/07/30 21:42:29 INFO impl.FsDatasetAsyncDiskService: Shutting down all async disk service threads
20/07/30 21:42:29 INFO impl.FsDatasetAsyncDiskService: All async disk service threads have been shut down
20/07/30 21:42:29 INFO namenode.FSNamesystem: Stopping services started for active state
20/07/30 21:42:29 INFO namenode.FSEditLog: Ending log segment 1
20/07/30 21:42:29 INFO namenode.FSEditLog: Number of transactions: 9 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 70 60 
20/07/30 21:42:29 INFO namenode.FileJournalManager: Finalizing edits file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/edits_inprogress_0000000000000000001 -> /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/edits_0000000000000000001-0000000000000000009
20/07/30 21:42:29 INFO namenode.FileJournalManager: Finalizing edits file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/edits_inprogress_0000000000000000001 -> /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/edits_0000000000000000001-0000000000000000009
20/07/30 21:42:29 INFO blockmanagement.BlockManager: Stopping ReplicationMonitor.
20/07/30 21:42:29 WARN blockmanagement.DecommissionManager: Monitor interrupted: java.lang.InterruptedException: sleep interrupted
20/07/30 21:42:29 INFO namenode.FSNamesystem: Stopping services started for active state
20/07/30 21:42:29 INFO namenode.FSNamesystem: Stopping services started for standby state
20/07/30 21:42:29 INFO ipc.Server: Stopping server on 38933
20/07/30 21:42:29 INFO ipc.Server: Stopping IPC Server listener on 38933
20/07/30 21:42:29 INFO ipc.Server: Stopping IPC Server Responder
20/07/30 21:42:29 INFO mortbay.log: Stopped SelectChannelConnector@localhost:0
20/07/30 21:42:29 INFO impl.MetricsSystemImpl: Stopping DataNode metrics system...
20/07/30 21:42:29 INFO impl.MetricsSystemImpl: DataNode metrics system stopped.
20/07/30 21:42:29 INFO impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
20/07/30 21:42:29 INFO server.HiveServer2: Shutting down HiveServer2
20/07/30 21:42:29 INFO thrift.ThriftCLIService: Thrift server has stopped
20/07/30 21:42:29 INFO service.AbstractService: Service:ThriftBinaryCLIService is stopped.
20/07/30 21:42:29 INFO service.AbstractService: Service:OperationManager is stopped.
20/07/30 21:42:29 INFO service.AbstractService: Service:SessionManager is stopped.
20/07/30 21:42:39 INFO service.AbstractService: Service:CLIService is stopped.
20/07/30 21:42:39 INFO service.AbstractService: Service:HiveServer2 is stopped.
Jul 30, 2020 9:42:39 PM com.spotify.beetest.TestMiniCluster setUp
INFO: STARTING CLUSTER at: /tmp/MiniClusterTest-239445528
20/07/30 21:42:39 WARN conf.HiveConf: HiveConf of name hive.root.logger does not exist
20/07/30 21:42:39 INFO hdfs.MiniDFSCluster: starting cluster with 1 namenodes.
Formatting using clusterid: testClusterID
20/07/30 21:42:39 INFO namenode.HostFileManager: read includes:
HostSet(
)
20/07/30 21:42:39 INFO namenode.HostFileManager: read excludes:
HostSet(
)
20/07/30 21:42:39 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/07/30 21:42:39 INFO util.GSet: Computing capacity for map BlocksMap
20/07/30 21:42:39 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:39 INFO util.GSet: 2.0% max memory = 1.1 GB
20/07/30 21:42:39 INFO util.GSet: capacity      = 2^22 = 4194304 entries
20/07/30 21:42:39 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/07/30 21:42:39 INFO blockmanagement.BlockManager: defaultReplication         = 1
20/07/30 21:42:39 INFO blockmanagement.BlockManager: maxReplication             = 512
20/07/30 21:42:39 INFO blockmanagement.BlockManager: minReplication             = 1
20/07/30 21:42:39 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/07/30 21:42:39 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/07/30 21:42:39 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/07/30 21:42:39 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/07/30 21:42:39 INFO namenode.FSNamesystem: fsOwner             = jdbl (auth:SIMPLE)
20/07/30 21:42:39 INFO namenode.FSNamesystem: supergroup          = supergroup
20/07/30 21:42:39 INFO namenode.FSNamesystem: isPermissionEnabled = false
20/07/30 21:42:39 INFO namenode.FSNamesystem: HA Enabled: false
20/07/30 21:42:39 INFO namenode.FSNamesystem: Append Enabled: true
20/07/30 21:42:39 INFO util.GSet: Computing capacity for map INodeMap
20/07/30 21:42:39 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:39 INFO util.GSet: 1.0% max memory = 1.1 GB
20/07/30 21:42:39 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/07/30 21:42:39 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/07/30 21:42:39 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/07/30 21:42:39 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/07/30 21:42:39 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
20/07/30 21:42:39 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/07/30 21:42:39 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/07/30 21:42:39 INFO util.GSet: Computing capacity for map Namenode Retry Cache
20/07/30 21:42:39 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:39 INFO util.GSet: 0.029999999329447746% max memory = 1.1 GB
20/07/30 21:42:39 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/07/30 21:42:40 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/name1 has been successfully formatted.
20/07/30 21:42:40 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/name2 has been successfully formatted.
20/07/30 21:42:40 INFO namenode.FSImage: Saving image file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/fsimage.ckpt_0000000000000000000 using no compression
20/07/30 21:42:40 INFO namenode.FSImage: Saving image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage.ckpt_0000000000000000000 using no compression
20/07/30 21:42:40 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/fsimage.ckpt_0000000000000000000 of size 196 bytes saved in 0 seconds.
20/07/30 21:42:40 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage.ckpt_0000000000000000000 of size 196 bytes saved in 0 seconds.
20/07/30 21:42:40 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
20/07/30 21:42:40 WARN impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
20/07/30 21:42:40 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
20/07/30 21:42:40 INFO impl.MetricsSystemImpl: NameNode metrics system started
20/07/30 21:42:40 INFO http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
20/07/30 21:42:40 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
20/07/30 21:42:40 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20/07/30 21:42:40 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
20/07/30 21:42:40 INFO http.HttpServer: dfs.webhdfs.enabled = false
20/07/30 21:42:40 INFO http.HttpServer: Jetty bound to port 35159
20/07/30 21:42:40 INFO mortbay.log: jetty-6.1.26
20/07/30 21:42:40 INFO mortbay.log: Extract jar:file:/home/jdbl/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_35159_hdfs____t7htp9/webapp
20/07/30 21:42:40 INFO mortbay.log: Started SelectChannelConnector@localhost:35159
20/07/30 21:42:40 INFO namenode.NameNode: Web-server up at: localhost:35159
20/07/30 21:42:40 INFO namenode.HostFileManager: read includes:
HostSet(
)
20/07/30 21:42:40 INFO namenode.HostFileManager: read excludes:
HostSet(
)
20/07/30 21:42:40 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/07/30 21:42:40 INFO util.GSet: Computing capacity for map BlocksMap
20/07/30 21:42:40 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:40 INFO util.GSet: 2.0% max memory = 1.1 GB
20/07/30 21:42:40 INFO util.GSet: capacity      = 2^22 = 4194304 entries
20/07/30 21:42:40 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/07/30 21:42:40 INFO blockmanagement.BlockManager: defaultReplication         = 1
20/07/30 21:42:40 INFO blockmanagement.BlockManager: maxReplication             = 512
20/07/30 21:42:40 INFO blockmanagement.BlockManager: minReplication             = 1
20/07/30 21:42:40 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/07/30 21:42:40 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/07/30 21:42:40 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/07/30 21:42:40 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/07/30 21:42:40 INFO namenode.FSNamesystem: fsOwner             = jdbl (auth:SIMPLE)
20/07/30 21:42:40 INFO namenode.FSNamesystem: supergroup          = supergroup
20/07/30 21:42:40 INFO namenode.FSNamesystem: isPermissionEnabled = false
20/07/30 21:42:40 INFO namenode.FSNamesystem: HA Enabled: false
20/07/30 21:42:40 INFO namenode.FSNamesystem: Append Enabled: true
20/07/30 21:42:40 INFO util.GSet: Computing capacity for map INodeMap
20/07/30 21:42:40 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:40 INFO util.GSet: 1.0% max memory = 1.1 GB
20/07/30 21:42:40 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/07/30 21:42:40 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/07/30 21:42:40 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/07/30 21:42:40 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/07/30 21:42:40 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
20/07/30 21:42:40 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/07/30 21:42:40 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/07/30 21:42:40 INFO util.GSet: Computing capacity for map Namenode Retry Cache
20/07/30 21:42:40 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:40 INFO util.GSet: 0.029999999329447746% max memory = 1.1 GB
20/07/30 21:42:40 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/07/30 21:42:40 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/name1/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:40 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/name2/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:40 INFO namenode.FileJournalManager: Recovering unfinalized segments in /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current
20/07/30 21:42:40 INFO namenode.FileJournalManager: Recovering unfinalized segments in /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current
20/07/30 21:42:40 INFO namenode.FSImage: No edit log streams selected.
20/07/30 21:42:40 INFO namenode.FSImage: Loading image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000 using no compression
20/07/30 21:42:40 INFO namenode.FSImage: Number of files = 1
20/07/30 21:42:40 INFO namenode.FSImage: Number of files under construction = 0
20/07/30 21:42:40 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000 of size 196 bytes loaded in 0 seconds.
20/07/30 21:42:40 INFO namenode.FSImage: Loaded image for txid 0 from /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000
20/07/30 21:42:40 INFO namenode.FSEditLog: Starting log segment at 1
20/07/30 21:42:40 INFO namenode.NameCache: initialized with 0 entries 0 lookups
20/07/30 21:42:40 INFO namenode.FSNamesystem: Finished loading FSImage in 126 msecs
20/07/30 21:42:40 INFO namenode.NameNode: RPC server is binding to localhost:0
20/07/30 21:42:40 INFO ipc.Server: Starting Socket Reader #1 for port 36649
20/07/30 21:42:40 INFO namenode.FSNamesystem: Registered FSNamesystemState MBean
20/07/30 21:42:40 INFO namenode.FSNamesystem: Number of blocks under construction: 0
20/07/30 21:42:40 INFO namenode.FSNamesystem: Number of blocks under construction: 0
20/07/30 21:42:40 INFO namenode.FSNamesystem: initializing replication queues
20/07/30 21:42:40 INFO blockmanagement.BlockManager: Total number of blocks            = 0
20/07/30 21:42:40 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0
20/07/30 21:42:40 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0
20/07/30 21:42:40 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0
20/07/30 21:42:40 INFO blockmanagement.BlockManager: Number of blocks being written    = 0
20/07/30 21:42:40 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
20/07/30 21:42:40 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs
20/07/30 21:42:40 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
20/07/30 21:42:40 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
20/07/30 21:42:40 WARN util.MBeans: Failed to register MBean "Hadoop:service=NameNode,name=NameNodeInfo": Instance already exists.
20/07/30 21:42:40 INFO ipc.Server: IPC Server Responder: starting
20/07/30 21:42:40 INFO ipc.Server: IPC Server listener on 36649: starting
20/07/30 21:42:40 INFO namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:36649
20/07/30 21:42:40 INFO namenode.FSNamesystem: Starting services required for active state
20/07/30 21:42:40 INFO hdfs.MiniDFSCluster: Starting DataNode 0 with dfs.datanode.data.dir: file:/tmp/MiniClusterTest-239445528/BeetestCluster/data/data1,file:/tmp/MiniClusterTest-239445528/BeetestCluster/data/data2
20/07/30 21:42:40 INFO impl.MetricsSystemImpl: DataNode metrics system started (again)
20/07/30 21:42:40 INFO datanode.DataNode: Configured hostname is 127.0.0.1
20/07/30 21:42:40 WARN util.MBeans: Failed to register MBean "Hadoop:service=DataNode,name=DataNodeInfo": Instance already exists.
20/07/30 21:42:40 INFO datanode.DataNode: Opened streaming server at /127.0.0.1:33189
20/07/30 21:42:40 INFO datanode.DataNode: Balancing bandwith is 1048576 bytes/s
20/07/30 21:42:40 INFO http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
20/07/30 21:42:40 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
20/07/30 21:42:40 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
20/07/30 21:42:40 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20/07/30 21:42:40 INFO datanode.DataNode: Opened info server at localhost:0
20/07/30 21:42:40 INFO datanode.DataNode: dfs.webhdfs.enabled = false
20/07/30 21:42:40 INFO http.HttpServer: Jetty bound to port 39911
20/07/30 21:42:40 INFO mortbay.log: jetty-6.1.26
20/07/30 21:42:40 INFO mortbay.log: Extract jar:file:/home/jdbl/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_39911_datanode____.g47v6u/webapp
20/07/30 21:42:40 INFO mortbay.log: Started SelectChannelConnector@localhost:39911
20/07/30 21:42:40 INFO ipc.Server: Starting Socket Reader #1 for port 38841
20/07/30 21:42:40 INFO datanode.DataNode: Opened IPC server at /127.0.0.1:38841
20/07/30 21:42:40 INFO datanode.DataNode: Refresh request received for nameservices: null
20/07/30 21:42:40 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>
20/07/30 21:42:40 INFO datanode.DataNode: Block pool <registering> (storage id unknown) service to localhost/127.0.0.1:36649 starting to offer service
20/07/30 21:42:40 INFO ipc.Server: IPC Server Responder: starting
20/07/30 21:42:40 INFO ipc.Server: IPC Server listener on 38841: starting
20/07/30 21:42:40 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:42:40 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:40 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1 is not formatted
20/07/30 21:42:40 INFO common.Storage: Formatting ...
20/07/30 21:42:40 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:40 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2 is not formatted
20/07/30 21:42:40 INFO common.Storage: Formatting ...
20/07/30 21:42:40 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:42:40 INFO common.Storage: Locking is disabled
20/07/30 21:42:40 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current/BP-1258967324-172.17.0.16-1596145359778 is not formatted.
20/07/30 21:42:40 INFO common.Storage: Formatting ...
20/07/30 21:42:40 INFO common.Storage: Formatting block pool BP-1258967324-172.17.0.16-1596145359778 directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current/BP-1258967324-172.17.0.16-1596145359778/current
20/07/30 21:42:40 INFO common.Storage: Locking is disabled
20/07/30 21:42:40 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current/BP-1258967324-172.17.0.16-1596145359778 is not formatted.
20/07/30 21:42:40 INFO common.Storage: Formatting ...
20/07/30 21:42:40 INFO common.Storage: Formatting block pool BP-1258967324-172.17.0.16-1596145359778 directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current/BP-1258967324-172.17.0.16-1596145359778/current
20/07/30 21:42:40 INFO datanode.DataNode: Setting up storage: nsid=1309239164;bpid=BP-1258967324-172.17.0.16-1596145359778;lv=-47;nsInfo=lv=-47;cid=testClusterID;nsid=1309239164;c=0;bpid=BP-1258967324-172.17.0.16-1596145359778
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Added volume - /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Added volume - /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean
20/07/30 21:42:40 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1596148454813 with interval 21600000
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Adding block pool BP-1258967324-172.17.0.16-1596145359778
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Scanning block pool BP-1258967324-172.17.0.16-1596145359778 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current...
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Scanning block pool BP-1258967324-172.17.0.16-1596145359778 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current...
20/07/30 21:42:40 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-1258967324-172.17.0.16-1596145359778 on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current: 40ms
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-1258967324-172.17.0.16-1596145359778 on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current: 52ms
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1258967324-172.17.0.16-1596145359778: 72ms
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-1258967324-172.17.0.16-1596145359778 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current...
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1258967324-172.17.0.16-1596145359778 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current: 0ms
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-1258967324-172.17.0.16-1596145359778 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current...
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1258967324-172.17.0.16-1596145359778 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current: 0ms
20/07/30 21:42:40 INFO impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
20/07/30 21:42:40 INFO datanode.DataNode: Block pool BP-1258967324-172.17.0.16-1596145359778 (storage id DS-2084900750-172.17.0.16-33189-1596145360695) service to localhost/127.0.0.1:36649 beginning handshake with NN
20/07/30 21:42:40 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-2084900750-172.17.0.16-33189-1596145360695, infoPort=39911, ipcPort=38841, storageInfo=lv=-47;cid=testClusterID;nsid=1309239164;c=0) storage DS-2084900750-172.17.0.16-33189-1596145360695
20/07/30 21:42:40 INFO net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:33189
20/07/30 21:42:40 INFO datanode.DataNode: Block pool Block pool BP-1258967324-172.17.0.16-1596145359778 (storage id DS-2084900750-172.17.0.16-33189-1596145360695) service to localhost/127.0.0.1:36649 successfully registered with NN
20/07/30 21:42:40 INFO datanode.DataNode: For namenode localhost/127.0.0.1:36649 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec Initial delay: 0msec; heartBeatInterval=3000
20/07/30 21:42:40 INFO datanode.DataNode: Namenode Block pool BP-1258967324-172.17.0.16-1596145359778 (storage id DS-2084900750-172.17.0.16-33189-1596145360695) service to localhost/127.0.0.1:36649 trying to claim ACTIVE state with txid=1
20/07/30 21:42:40 INFO datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1258967324-172.17.0.16-1596145359778 (storage id DS-2084900750-172.17.0.16-33189-1596145360695) service to localhost/127.0.0.1:36649
20/07/30 21:42:40 INFO blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:33189 after starting up or becoming active. Its block contents are no longer considered stale
20/07/30 21:42:40 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-2084900750-172.17.0.16-33189-1596145360695, infoPort=39911, ipcPort=38841, storageInfo=lv=-47;cid=testClusterID;nsid=1309239164;c=0), blocks: 0, processing time: 0 msecs
20/07/30 21:42:40 INFO datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 6 msecs for RPC and NN processing
20/07/30 21:42:40 INFO datanode.DataNode: sent block report, processed command:org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@6b96589e
20/07/30 21:42:40 INFO util.GSet: Computing capacity for map BlockMap
20/07/30 21:42:40 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:40 INFO util.GSet: 0.5% max memory = 1.1 GB
20/07/30 21:42:40 INFO util.GSet: capacity      = 2^20 = 1048576 entries
20/07/30 21:42:40 INFO datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-1258967324-172.17.0.16-1596145359778
20/07/30 21:42:40 INFO datanode.DataBlockScanner: Added bpid=BP-1258967324-172.17.0.16-1596145359778 to blockPoolScannerMap, new size=1
20/07/30 21:42:40 INFO hdfs.MiniDFSCluster: Cluster is active
20/07/30 21:42:41 INFO hive.metastore: Mestastore configuration hive.metastore.warehouse.dir changed from hdfs://localhost:38933/tmp/beetest/warehouse to hdfs://localhost:36649/tmp/beetest/warehouse
20/07/30 21:42:41 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
20/07/30 21:42:41 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Shutting down the object store...	
20/07/30 21:42:41 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
20/07/30 21:42:41 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
20/07/30 21:42:41 INFO session.SessionState: Created HDFS directory: hdfs://localhost:36649/tmp/beetest/scratchdir/jdbl
20/07/30 21:42:41 INFO session.SessionState: Created local directory: /tmp/MiniClusterTest-239445528/localScratchDir
20/07/30 21:42:41 INFO session.SessionState: Created local directory: /tmp/a5ec7292-f6c5-45d1-8b2b-9ee208a697b1_resources
20/07/30 21:42:41 INFO session.SessionState: Created HDFS directory: hdfs://localhost:36649/tmp/beetest/scratchdir/jdbl/a5ec7292-f6c5-45d1-8b2b-9ee208a697b1
20/07/30 21:42:41 INFO session.SessionState: Created local directory: /tmp/MiniClusterTest-239445528/localScratchDir/a5ec7292-f6c5-45d1-8b2b-9ee208a697b1
20/07/30 21:42:41 INFO session.SessionState: Created HDFS directory: hdfs://localhost:36649/tmp/beetest/scratchdir/jdbl/a5ec7292-f6c5-45d1-8b2b-9ee208a697b1/_tmp_space.db
20/07/30 21:42:41 INFO service.CompositeService: Operation log root directory is created: /tmp/jdbl/operation_logs
20/07/30 21:42:41 INFO service.CompositeService: HiveServer2: Background operation thread pool size: 100
20/07/30 21:42:41 INFO service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
20/07/30 21:42:41 INFO service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
20/07/30 21:42:41 INFO service.AbstractService: Service:OperationManager is inited.
20/07/30 21:42:41 INFO service.AbstractService: Service:SessionManager is inited.
20/07/30 21:42:41 INFO service.AbstractService: Service:CLIService is inited.
20/07/30 21:42:41 INFO service.AbstractService: Service:ThriftBinaryCLIService is inited.
20/07/30 21:42:41 INFO service.AbstractService: Service:HiveServer2 is inited.
20/07/30 21:42:41 INFO service.AbstractService: Service:OperationManager is started.
20/07/30 21:42:41 INFO service.AbstractService: Service:SessionManager is started.
20/07/30 21:42:41 INFO service.AbstractService: Service:CLIService is started.
20/07/30 21:42:41 INFO metastore.HiveMetaStore: 0: get_databases: default
20/07/30 21:42:41 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_databases: default	
20/07/30 21:42:41 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
20/07/30 21:42:41 INFO metastore.ObjectStore: ObjectStore, initialize called
20/07/30 21:42:41 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
20/07/30 21:42:41 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/07/30 21:42:41 INFO metastore.ObjectStore: Initialized ObjectStore
20/07/30 21:42:41 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
20/07/30 21:42:41 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Shutting down the object store...	
20/07/30 21:42:41 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
20/07/30 21:42:41 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
20/07/30 21:42:41 INFO service.AbstractService: Service:ThriftBinaryCLIService is started.
20/07/30 21:42:41 INFO service.AbstractService: Service:HiveServer2 is started.
20/07/30 21:42:41 INFO Configuration.deprecation: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
20/07/30 21:42:41 INFO Configuration.deprecation: dfs.safemode.extension is deprecated. Instead, use dfs.namenode.safemode.extension
20/07/30 21:42:41 INFO Configuration.deprecation: dfs.http.address is deprecated. Instead, use dfs.namenode.http-address
20/07/30 21:42:41 INFO Configuration.deprecation: slave.host.name is deprecated. Instead, use dfs.datanode.hostname
20/07/30 21:42:41 INFO Configuration.deprecation: dfs.umaskmode is deprecated. Instead, use fs.permissions.umask-mode
20/07/30 21:42:41 INFO Configuration.deprecation: dfs.permissions is deprecated. Instead, use dfs.permissions.enabled
20/07/30 21:42:41 INFO Configuration.deprecation: dfs.name.dir is deprecated. Instead, use dfs.namenode.name.dir
20/07/30 21:42:41 INFO Configuration.deprecation: dfs.data.dir is deprecated. Instead, use dfs.datanode.data.dir
20/07/30 21:42:41 INFO Configuration.deprecation: fs.checkpoint.dir is deprecated. Instead, use dfs.namenode.checkpoint.dir
20/07/30 21:42:41 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
20/07/30 21:42:41 INFO thrift.ThriftCLIService: Starting ThriftBinaryCLIService on port 39275 with 5...500 worker threads
Jul 30, 2020 9:42:41 PM com.spotify.beetest.TestMiniCluster testClusterCreation
INFO: URI: hdfs://localhost:36649
Jul 30, 2020 9:42:41 PM com.spotify.beetest.TestMiniCluster tearDown
INFO: STOPPING CLUSTER
20/07/30 21:42:41 INFO hdfs.MiniDFSCluster: Shutting down the Mini HDFS Cluster
20/07/30 21:42:41 INFO hdfs.MiniDFSCluster: Shutting down DataNode 0
20/07/30 21:42:41 WARN datanode.DirectoryScanner: DirectoryScanner: shutdown has been called
20/07/30 21:42:41 INFO mortbay.log: Stopped SelectChannelConnector@localhost:0
20/07/30 21:42:41 INFO ipc.Server: Stopping server on 38841
20/07/30 21:42:41 INFO ipc.Server: Stopping IPC Server listener on 38841
20/07/30 21:42:41 INFO ipc.Server: Stopping IPC Server Responder
20/07/30 21:42:41 INFO datanode.DataNode: Waiting for threadgroup to exit, active threads is 1
20/07/30 21:42:41 WARN datanode.DataNode: BPOfferService for Block pool BP-1258967324-172.17.0.16-1596145359778 (storage id DS-2084900750-172.17.0.16-33189-1596145360695) service to localhost/127.0.0.1:36649 interrupted
20/07/30 21:42:41 WARN datanode.DataNode: Ending block pool service for: Block pool BP-1258967324-172.17.0.16-1596145359778 (storage id DS-2084900750-172.17.0.16-33189-1596145360695) service to localhost/127.0.0.1:36649
20/07/30 21:42:41 INFO datanode.DataNode: Removed Block pool BP-1258967324-172.17.0.16-1596145359778 (storage id DS-2084900750-172.17.0.16-33189-1596145360695)
20/07/30 21:42:41 INFO datanode.DataBlockScanner: Removed bpid=BP-1258967324-172.17.0.16-1596145359778 from blockPoolScannerMap
20/07/30 21:42:41 INFO impl.FsDatasetImpl: Removing block pool BP-1258967324-172.17.0.16-1596145359778
20/07/30 21:42:41 INFO impl.FsDatasetAsyncDiskService: Shutting down all async disk service threads
20/07/30 21:42:41 INFO impl.FsDatasetAsyncDiskService: All async disk service threads have been shut down
20/07/30 21:42:41 INFO namenode.FSNamesystem: Stopping services started for active state
20/07/30 21:42:41 INFO namenode.FSEditLog: Ending log segment 1
20/07/30 21:42:41 INFO namenode.FSEditLog: Number of transactions: 9 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 87 82 
20/07/30 21:42:41 INFO namenode.FileJournalManager: Finalizing edits file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/edits_inprogress_0000000000000000001 -> /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/edits_0000000000000000001-0000000000000000009
20/07/30 21:42:41 INFO namenode.FileJournalManager: Finalizing edits file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/edits_inprogress_0000000000000000001 -> /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/edits_0000000000000000001-0000000000000000009
20/07/30 21:42:41 INFO blockmanagement.BlockManager: Stopping ReplicationMonitor.
20/07/30 21:42:41 WARN blockmanagement.DecommissionManager: Monitor interrupted: java.lang.InterruptedException: sleep interrupted
20/07/30 21:42:41 INFO namenode.FSNamesystem: Stopping services started for active state
20/07/30 21:42:41 INFO namenode.FSNamesystem: Stopping services started for standby state
20/07/30 21:42:41 INFO ipc.Server: Stopping server on 36649
20/07/30 21:42:41 INFO ipc.Server: Stopping IPC Server listener on 36649
20/07/30 21:42:41 INFO ipc.Server: Stopping IPC Server Responder
20/07/30 21:42:41 INFO mortbay.log: Stopped SelectChannelConnector@localhost:0
20/07/30 21:42:41 INFO impl.MetricsSystemImpl: Stopping DataNode metrics system...
20/07/30 21:42:41 INFO impl.MetricsSystemImpl: DataNode metrics system stopped.
20/07/30 21:42:41 INFO impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
20/07/30 21:42:41 INFO server.HiveServer2: Shutting down HiveServer2
20/07/30 21:42:41 INFO thrift.ThriftCLIService: Thrift server has stopped
20/07/30 21:42:41 INFO service.AbstractService: Service:ThriftBinaryCLIService is stopped.
20/07/30 21:42:41 INFO service.AbstractService: Service:OperationManager is stopped.
20/07/30 21:42:41 INFO service.AbstractService: Service:SessionManager is stopped.
20/07/30 21:42:51 INFO service.AbstractService: Service:CLIService is stopped.
20/07/30 21:42:51 INFO service.AbstractService: Service:HiveServer2 is stopped.
Jul 30, 2020 9:42:51 PM com.spotify.beetest.TestMiniCluster setUp
INFO: STARTING CLUSTER at: /tmp/MiniClusterTest-239445528
20/07/30 21:42:51 WARN conf.HiveConf: HiveConf of name hive.root.logger does not exist
20/07/30 21:42:51 INFO hdfs.MiniDFSCluster: starting cluster with 1 namenodes.
Formatting using clusterid: testClusterID
20/07/30 21:42:51 INFO namenode.HostFileManager: read includes:
HostSet(
)
20/07/30 21:42:51 INFO namenode.HostFileManager: read excludes:
HostSet(
)
20/07/30 21:42:51 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/07/30 21:42:51 INFO util.GSet: Computing capacity for map BlocksMap
20/07/30 21:42:51 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:51 INFO util.GSet: 2.0% max memory = 1.1 GB
20/07/30 21:42:51 INFO util.GSet: capacity      = 2^22 = 4194304 entries
20/07/30 21:42:51 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/07/30 21:42:51 INFO blockmanagement.BlockManager: defaultReplication         = 1
20/07/30 21:42:51 INFO blockmanagement.BlockManager: maxReplication             = 512
20/07/30 21:42:51 INFO blockmanagement.BlockManager: minReplication             = 1
20/07/30 21:42:51 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/07/30 21:42:51 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/07/30 21:42:51 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/07/30 21:42:51 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/07/30 21:42:51 INFO namenode.FSNamesystem: fsOwner             = jdbl (auth:SIMPLE)
20/07/30 21:42:51 INFO namenode.FSNamesystem: supergroup          = supergroup
20/07/30 21:42:51 INFO namenode.FSNamesystem: isPermissionEnabled = false
20/07/30 21:42:51 INFO namenode.FSNamesystem: HA Enabled: false
20/07/30 21:42:51 INFO namenode.FSNamesystem: Append Enabled: true
20/07/30 21:42:51 INFO util.GSet: Computing capacity for map INodeMap
20/07/30 21:42:51 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:51 INFO util.GSet: 1.0% max memory = 1.1 GB
20/07/30 21:42:51 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/07/30 21:42:51 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/07/30 21:42:51 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/07/30 21:42:51 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/07/30 21:42:51 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
20/07/30 21:42:51 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/07/30 21:42:51 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/07/30 21:42:51 INFO util.GSet: Computing capacity for map Namenode Retry Cache
20/07/30 21:42:51 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:51 INFO util.GSet: 0.029999999329447746% max memory = 1.1 GB
20/07/30 21:42:51 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/07/30 21:42:51 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/name1 has been successfully formatted.
20/07/30 21:42:51 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/name2 has been successfully formatted.
20/07/30 21:42:51 INFO namenode.FSImage: Saving image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage.ckpt_0000000000000000000 using no compression
20/07/30 21:42:51 INFO namenode.FSImage: Saving image file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/fsimage.ckpt_0000000000000000000 using no compression
20/07/30 21:42:51 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/fsimage.ckpt_0000000000000000000 of size 196 bytes saved in 0 seconds.
20/07/30 21:42:51 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage.ckpt_0000000000000000000 of size 196 bytes saved in 0 seconds.
20/07/30 21:42:51 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
20/07/30 21:42:51 WARN impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
20/07/30 21:42:51 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
20/07/30 21:42:51 INFO impl.MetricsSystemImpl: NameNode metrics system started
20/07/30 21:42:51 INFO http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
20/07/30 21:42:51 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
20/07/30 21:42:51 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
20/07/30 21:42:51 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20/07/30 21:42:51 INFO http.HttpServer: dfs.webhdfs.enabled = false
20/07/30 21:42:51 INFO http.HttpServer: Jetty bound to port 35629
20/07/30 21:42:51 INFO mortbay.log: jetty-6.1.26
20/07/30 21:42:51 INFO mortbay.log: Extract jar:file:/home/jdbl/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_35629_hdfs____wffbb9/webapp
20/07/30 21:42:51 INFO mortbay.log: Started SelectChannelConnector@localhost:35629
20/07/30 21:42:51 INFO namenode.NameNode: Web-server up at: localhost:35629
20/07/30 21:42:51 INFO namenode.HostFileManager: read includes:
HostSet(
)
20/07/30 21:42:51 INFO namenode.HostFileManager: read excludes:
HostSet(
)
20/07/30 21:42:51 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/07/30 21:42:51 INFO util.GSet: Computing capacity for map BlocksMap
20/07/30 21:42:51 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:51 INFO util.GSet: 2.0% max memory = 1.1 GB
20/07/30 21:42:51 INFO util.GSet: capacity      = 2^22 = 4194304 entries
20/07/30 21:42:51 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/07/30 21:42:51 INFO blockmanagement.BlockManager: defaultReplication         = 1
20/07/30 21:42:51 INFO blockmanagement.BlockManager: maxReplication             = 512
20/07/30 21:42:51 INFO blockmanagement.BlockManager: minReplication             = 1
20/07/30 21:42:51 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/07/30 21:42:51 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/07/30 21:42:51 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/07/30 21:42:51 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/07/30 21:42:51 INFO namenode.FSNamesystem: fsOwner             = jdbl (auth:SIMPLE)
20/07/30 21:42:51 INFO namenode.FSNamesystem: supergroup          = supergroup
20/07/30 21:42:51 INFO namenode.FSNamesystem: isPermissionEnabled = false
20/07/30 21:42:51 INFO namenode.FSNamesystem: HA Enabled: false
20/07/30 21:42:51 INFO namenode.FSNamesystem: Append Enabled: true
20/07/30 21:42:51 INFO util.GSet: Computing capacity for map INodeMap
20/07/30 21:42:51 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:51 INFO util.GSet: 1.0% max memory = 1.1 GB
20/07/30 21:42:51 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/07/30 21:42:51 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/07/30 21:42:51 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/07/30 21:42:51 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/07/30 21:42:51 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
20/07/30 21:42:51 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/07/30 21:42:51 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/07/30 21:42:51 INFO util.GSet: Computing capacity for map Namenode Retry Cache
20/07/30 21:42:51 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:51 INFO util.GSet: 0.029999999329447746% max memory = 1.1 GB
20/07/30 21:42:51 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/07/30 21:42:51 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/name1/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:51 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/name2/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:51 INFO namenode.FileJournalManager: Recovering unfinalized segments in /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current
20/07/30 21:42:51 INFO namenode.FileJournalManager: Recovering unfinalized segments in /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current
20/07/30 21:42:51 INFO namenode.FSImage: No edit log streams selected.
20/07/30 21:42:51 INFO namenode.FSImage: Loading image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000 using no compression
20/07/30 21:42:51 INFO namenode.FSImage: Number of files = 1
20/07/30 21:42:51 INFO namenode.FSImage: Number of files under construction = 0
20/07/30 21:42:51 INFO namenode.FSImage: Image file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000 of size 196 bytes loaded in 0 seconds.
20/07/30 21:42:51 INFO namenode.FSImage: Loaded image for txid 0 from /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/fsimage_0000000000000000000
20/07/30 21:42:51 INFO namenode.FSEditLog: Starting log segment at 1
20/07/30 21:42:51 INFO namenode.NameCache: initialized with 0 entries 0 lookups
20/07/30 21:42:51 INFO namenode.FSNamesystem: Finished loading FSImage in 93 msecs
20/07/30 21:42:51 INFO namenode.NameNode: RPC server is binding to localhost:0
20/07/30 21:42:51 INFO ipc.Server: Starting Socket Reader #1 for port 44047
20/07/30 21:42:51 INFO namenode.FSNamesystem: Registered FSNamesystemState MBean
20/07/30 21:42:51 INFO namenode.FSNamesystem: Number of blocks under construction: 0
20/07/30 21:42:51 INFO namenode.FSNamesystem: Number of blocks under construction: 0
20/07/30 21:42:51 INFO namenode.FSNamesystem: initializing replication queues
20/07/30 21:42:51 INFO blockmanagement.BlockManager: Total number of blocks            = 0
20/07/30 21:42:51 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0
20/07/30 21:42:51 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0
20/07/30 21:42:51 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0
20/07/30 21:42:51 INFO blockmanagement.BlockManager: Number of blocks being written    = 0
20/07/30 21:42:51 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
20/07/30 21:42:51 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs
20/07/30 21:42:51 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
20/07/30 21:42:51 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
20/07/30 21:42:51 WARN util.MBeans: Failed to register MBean "Hadoop:service=NameNode,name=NameNodeInfo": Instance already exists.
20/07/30 21:42:51 INFO ipc.Server: IPC Server Responder: starting
20/07/30 21:42:51 INFO ipc.Server: IPC Server listener on 44047: starting
20/07/30 21:42:51 INFO namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:44047
20/07/30 21:42:51 INFO namenode.FSNamesystem: Starting services required for active state
20/07/30 21:42:51 INFO hdfs.MiniDFSCluster: Starting DataNode 0 with dfs.datanode.data.dir: file:/tmp/MiniClusterTest-239445528/BeetestCluster/data/data1,file:/tmp/MiniClusterTest-239445528/BeetestCluster/data/data2
20/07/30 21:42:51 INFO impl.MetricsSystemImpl: DataNode metrics system started (again)
20/07/30 21:42:51 INFO datanode.DataNode: Configured hostname is 127.0.0.1
20/07/30 21:42:51 WARN util.MBeans: Failed to register MBean "Hadoop:service=DataNode,name=DataNodeInfo": Instance already exists.
20/07/30 21:42:51 INFO datanode.DataNode: Opened streaming server at /127.0.0.1:38857
20/07/30 21:42:51 INFO datanode.DataNode: Balancing bandwith is 1048576 bytes/s
20/07/30 21:42:51 INFO http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
20/07/30 21:42:51 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
20/07/30 21:42:51 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
20/07/30 21:42:51 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20/07/30 21:42:51 INFO datanode.DataNode: Opened info server at localhost:0
20/07/30 21:42:51 INFO datanode.DataNode: dfs.webhdfs.enabled = false
20/07/30 21:42:51 INFO http.HttpServer: Jetty bound to port 42441
20/07/30 21:42:51 INFO mortbay.log: jetty-6.1.26
20/07/30 21:42:51 INFO mortbay.log: Extract jar:file:/home/jdbl/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_42441_datanode____.dcg0me/webapp
20/07/30 21:42:51 INFO mortbay.log: Started SelectChannelConnector@localhost:42441
20/07/30 21:42:51 INFO ipc.Server: Starting Socket Reader #1 for port 44135
20/07/30 21:42:51 INFO datanode.DataNode: Opened IPC server at /127.0.0.1:44135
20/07/30 21:42:51 INFO datanode.DataNode: Refresh request received for nameservices: null
20/07/30 21:42:51 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>
20/07/30 21:42:51 INFO datanode.DataNode: Block pool <registering> (storage id unknown) service to localhost/127.0.0.1:44047 starting to offer service
20/07/30 21:42:51 INFO ipc.Server: IPC Server Responder: starting
20/07/30 21:42:51 INFO ipc.Server: IPC Server listener on 44135: starting
20/07/30 21:42:51 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:42:51 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:51 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1 is not formatted
20/07/30 21:42:51 INFO common.Storage: Formatting ...
20/07/30 21:42:51 INFO common.Storage: Lock on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:42:51 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2 is not formatted
20/07/30 21:42:51 INFO common.Storage: Formatting ...
20/07/30 21:42:52 INFO common.Storage: Locking is disabled
20/07/30 21:42:52 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current/BP-1490076844-172.17.0.16-1596145371457 is not formatted.
20/07/30 21:42:52 INFO common.Storage: Formatting ...
20/07/30 21:42:52 INFO common.Storage: Formatting block pool BP-1490076844-172.17.0.16-1596145371457 directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current/BP-1490076844-172.17.0.16-1596145371457/current
20/07/30 21:42:52 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:42:52 INFO common.Storage: Locking is disabled
20/07/30 21:42:52 INFO common.Storage: Storage directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current/BP-1490076844-172.17.0.16-1596145371457 is not formatted.
20/07/30 21:42:52 INFO common.Storage: Formatting ...
20/07/30 21:42:52 INFO common.Storage: Formatting block pool BP-1490076844-172.17.0.16-1596145371457 directory /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current/BP-1490076844-172.17.0.16-1596145371457/current
20/07/30 21:42:52 INFO datanode.DataNode: Setting up storage: nsid=591684227;bpid=BP-1490076844-172.17.0.16-1596145371457;lv=-47;nsInfo=lv=-47;cid=testClusterID;nsid=591684227;c=0;bpid=BP-1490076844-172.17.0.16-1596145371457
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Added volume - /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Added volume - /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean
20/07/30 21:42:52 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1596158120058 with interval 21600000
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Adding block pool BP-1490076844-172.17.0.16-1596145371457
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Scanning block pool BP-1490076844-172.17.0.16-1596145371457 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current...
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Scanning block pool BP-1490076844-172.17.0.16-1596145371457 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current...
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-1490076844-172.17.0.16-1596145371457 on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current: 3ms
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-1490076844-172.17.0.16-1596145371457 on /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current: 4ms
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-1490076844-172.17.0.16-1596145371457: 4ms
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-1490076844-172.17.0.16-1596145371457 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current...
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1490076844-172.17.0.16-1596145371457 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data1/current: 0ms
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-1490076844-172.17.0.16-1596145371457 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current...
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-1490076844-172.17.0.16-1596145371457 on volume /tmp/MiniClusterTest-239445528/BeetestCluster/data/data2/current: 0ms
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
20/07/30 21:42:52 INFO datanode.DataNode: Block pool BP-1490076844-172.17.0.16-1596145371457 (storage id DS-1683995718-172.17.0.16-38857-1596145371964) service to localhost/127.0.0.1:44047 beginning handshake with NN
20/07/30 21:42:52 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1683995718-172.17.0.16-38857-1596145371964, infoPort=42441, ipcPort=44135, storageInfo=lv=-47;cid=testClusterID;nsid=591684227;c=0) storage DS-1683995718-172.17.0.16-38857-1596145371964
20/07/30 21:42:52 INFO net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:38857
20/07/30 21:42:52 INFO datanode.DataNode: Block pool Block pool BP-1490076844-172.17.0.16-1596145371457 (storage id DS-1683995718-172.17.0.16-38857-1596145371964) service to localhost/127.0.0.1:44047 successfully registered with NN
20/07/30 21:42:52 INFO datanode.DataNode: For namenode localhost/127.0.0.1:44047 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec Initial delay: 0msec; heartBeatInterval=3000
20/07/30 21:42:52 INFO datanode.DataNode: Namenode Block pool BP-1490076844-172.17.0.16-1596145371457 (storage id DS-1683995718-172.17.0.16-38857-1596145371964) service to localhost/127.0.0.1:44047 trying to claim ACTIVE state with txid=1
20/07/30 21:42:52 INFO datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-1490076844-172.17.0.16-1596145371457 (storage id DS-1683995718-172.17.0.16-38857-1596145371964) service to localhost/127.0.0.1:44047
20/07/30 21:42:52 INFO blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:38857 after starting up or becoming active. Its block contents are no longer considered stale
20/07/30 21:42:52 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1683995718-172.17.0.16-38857-1596145371964, infoPort=42441, ipcPort=44135, storageInfo=lv=-47;cid=testClusterID;nsid=591684227;c=0), blocks: 0, processing time: 1 msecs
20/07/30 21:42:52 INFO datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 2 msecs for RPC and NN processing
20/07/30 21:42:52 INFO datanode.DataNode: sent block report, processed command:org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@5b60f2f7
20/07/30 21:42:52 INFO util.GSet: Computing capacity for map BlockMap
20/07/30 21:42:52 INFO util.GSet: VM type       = 64-bit
20/07/30 21:42:52 INFO util.GSet: 0.5% max memory = 1.1 GB
20/07/30 21:42:52 INFO util.GSet: capacity      = 2^20 = 1048576 entries
20/07/30 21:42:52 INFO datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-1490076844-172.17.0.16-1596145371457
20/07/30 21:42:52 INFO datanode.DataBlockScanner: Added bpid=BP-1490076844-172.17.0.16-1596145371457 to blockPoolScannerMap, new size=1
20/07/30 21:42:52 INFO hdfs.MiniDFSCluster: Cluster is active
20/07/30 21:42:52 INFO hive.metastore: Mestastore configuration hive.metastore.warehouse.dir changed from hdfs://localhost:36649/tmp/beetest/warehouse to hdfs://localhost:44047/tmp/beetest/warehouse
20/07/30 21:42:52 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
20/07/30 21:42:52 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Shutting down the object store...	
20/07/30 21:42:52 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
20/07/30 21:42:52 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
20/07/30 21:42:52 INFO session.SessionState: Created HDFS directory: hdfs://localhost:44047/tmp/beetest/scratchdir/jdbl
20/07/30 21:42:52 INFO session.SessionState: Created local directory: /tmp/MiniClusterTest-239445528/localScratchDir
20/07/30 21:42:52 INFO session.SessionState: Created local directory: /tmp/00269582-130a-44ad-b815-de9967c867f6_resources
20/07/30 21:42:52 INFO session.SessionState: Created HDFS directory: hdfs://localhost:44047/tmp/beetest/scratchdir/jdbl/00269582-130a-44ad-b815-de9967c867f6
20/07/30 21:42:52 INFO session.SessionState: Created local directory: /tmp/MiniClusterTest-239445528/localScratchDir/00269582-130a-44ad-b815-de9967c867f6
20/07/30 21:42:52 INFO session.SessionState: Created HDFS directory: hdfs://localhost:44047/tmp/beetest/scratchdir/jdbl/00269582-130a-44ad-b815-de9967c867f6/_tmp_space.db
20/07/30 21:42:52 INFO service.CompositeService: Operation log root directory is created: /tmp/jdbl/operation_logs
20/07/30 21:42:52 INFO service.CompositeService: HiveServer2: Background operation thread pool size: 100
20/07/30 21:42:52 INFO service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
20/07/30 21:42:52 INFO service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
20/07/30 21:42:52 INFO service.AbstractService: Service:OperationManager is inited.
20/07/30 21:42:52 INFO service.AbstractService: Service:SessionManager is inited.
20/07/30 21:42:52 INFO service.AbstractService: Service:CLIService is inited.
20/07/30 21:42:52 INFO service.AbstractService: Service:ThriftBinaryCLIService is inited.
20/07/30 21:42:52 INFO service.AbstractService: Service:HiveServer2 is inited.
20/07/30 21:42:52 INFO service.AbstractService: Service:OperationManager is started.
20/07/30 21:42:52 INFO service.AbstractService: Service:SessionManager is started.
20/07/30 21:42:52 INFO service.AbstractService: Service:CLIService is started.
20/07/30 21:42:52 INFO metastore.HiveMetaStore: 0: get_databases: default
20/07/30 21:42:52 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_databases: default	
20/07/30 21:42:52 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
20/07/30 21:42:52 INFO metastore.ObjectStore: ObjectStore, initialize called
20/07/30 21:42:52 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
20/07/30 21:42:52 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/07/30 21:42:52 INFO metastore.ObjectStore: Initialized ObjectStore
20/07/30 21:42:52 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
20/07/30 21:42:52 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Shutting down the object store...	
20/07/30 21:42:52 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
20/07/30 21:42:52 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
20/07/30 21:42:52 INFO service.AbstractService: Service:ThriftBinaryCLIService is started.
20/07/30 21:42:52 INFO service.AbstractService: Service:HiveServer2 is started.
20/07/30 21:42:52 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
20/07/30 21:42:52 INFO thrift.ThriftCLIService: Starting ThriftBinaryCLIService on port 36971 with 5...500 worker threads
Jul 30, 2020 9:42:52 PM com.spotify.beetest.TestMiniCluster tearDown
INFO: STOPPING CLUSTER
20/07/30 21:42:52 INFO hdfs.MiniDFSCluster: Shutting down the Mini HDFS Cluster
20/07/30 21:42:52 INFO hdfs.MiniDFSCluster: Shutting down DataNode 0
20/07/30 21:42:52 WARN datanode.DirectoryScanner: DirectoryScanner: shutdown has been called
20/07/30 21:42:52 INFO mortbay.log: Stopped SelectChannelConnector@localhost:0
20/07/30 21:42:52 INFO ipc.Server: Stopping server on 44135
20/07/30 21:42:52 INFO ipc.Server: Stopping IPC Server listener on 44135
20/07/30 21:42:52 INFO ipc.Server: Stopping IPC Server Responder
20/07/30 21:42:52 INFO datanode.DataNode: Waiting for threadgroup to exit, active threads is 1
20/07/30 21:42:52 WARN datanode.DataNode: BPOfferService for Block pool BP-1490076844-172.17.0.16-1596145371457 (storage id DS-1683995718-172.17.0.16-38857-1596145371964) service to localhost/127.0.0.1:44047 interrupted
20/07/30 21:42:52 WARN datanode.DataNode: Ending block pool service for: Block pool BP-1490076844-172.17.0.16-1596145371457 (storage id DS-1683995718-172.17.0.16-38857-1596145371964) service to localhost/127.0.0.1:44047
20/07/30 21:42:52 INFO datanode.DataNode: Removed Block pool BP-1490076844-172.17.0.16-1596145371457 (storage id DS-1683995718-172.17.0.16-38857-1596145371964)
20/07/30 21:42:52 INFO datanode.DataBlockScanner: Removed bpid=BP-1490076844-172.17.0.16-1596145371457 from blockPoolScannerMap
20/07/30 21:42:52 INFO impl.FsDatasetImpl: Removing block pool BP-1490076844-172.17.0.16-1596145371457
20/07/30 21:42:52 INFO impl.FsDatasetAsyncDiskService: Shutting down all async disk service threads
20/07/30 21:42:52 INFO impl.FsDatasetAsyncDiskService: All async disk service threads have been shut down
20/07/30 21:42:52 INFO namenode.FSNamesystem: Stopping services started for active state
20/07/30 21:42:52 INFO namenode.FSEditLog: Ending log segment 1
20/07/30 21:42:52 INFO namenode.FSEditLog: Number of transactions: 9 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 76 78 
20/07/30 21:42:52 INFO namenode.FileJournalManager: Finalizing edits file /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/edits_inprogress_0000000000000000001 -> /tmp/MiniClusterTest-239445528/BeetestCluster/name1/current/edits_0000000000000000001-0000000000000000009
20/07/30 21:42:52 INFO namenode.FileJournalManager: Finalizing edits file /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/edits_inprogress_0000000000000000001 -> /tmp/MiniClusterTest-239445528/BeetestCluster/name2/current/edits_0000000000000000001-0000000000000000009
20/07/30 21:42:52 INFO blockmanagement.BlockManager: Stopping ReplicationMonitor.
20/07/30 21:42:52 WARN blockmanagement.DecommissionManager: Monitor interrupted: java.lang.InterruptedException: sleep interrupted
20/07/30 21:42:52 INFO namenode.FSNamesystem: Stopping services started for active state
20/07/30 21:42:52 INFO namenode.FSNamesystem: Stopping services started for standby state
20/07/30 21:42:52 INFO ipc.Server: Stopping server on 44047
20/07/30 21:42:52 INFO ipc.Server: Stopping IPC Server listener on 44047
20/07/30 21:42:52 INFO ipc.Server: Stopping IPC Server Responder
20/07/30 21:42:52 INFO mortbay.log: Stopped SelectChannelConnector@localhost:0
20/07/30 21:42:52 INFO impl.MetricsSystemImpl: Stopping DataNode metrics system...
20/07/30 21:42:52 INFO impl.MetricsSystemImpl: DataNode metrics system stopped.
20/07/30 21:42:52 INFO impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
20/07/30 21:42:52 INFO server.HiveServer2: Shutting down HiveServer2
20/07/30 21:42:52 INFO thrift.ThriftCLIService: Thrift server has stopped
20/07/30 21:42:52 INFO service.AbstractService: Service:ThriftBinaryCLIService is stopped.
20/07/30 21:42:52 INFO service.AbstractService: Service:OperationManager is stopped.
20/07/30 21:42:52 INFO service.AbstractService: Service:SessionManager is stopped.
20/07/30 21:43:02 INFO service.AbstractService: Service:CLIService is stopped.
20/07/30 21:43:02 INFO service.AbstractService: Service:HiveServer2 is stopped.
Tests run: 3, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.201 sec - in com.spotify.beetest.TestMiniCluster
Running com.spotify.beetest.TestHiveServer2
20/07/30 21:43:02 WARN conf.HiveConf: HiveConf of name hive.root.logger does not exist
20/07/30 21:43:02 INFO hdfs.MiniDFSCluster: starting cluster with 1 namenodes.
Formatting using clusterid: testClusterID
20/07/30 21:43:02 INFO namenode.HostFileManager: read includes:
HostSet(
)
20/07/30 21:43:02 INFO namenode.HostFileManager: read excludes:
HostSet(
)
20/07/30 21:43:02 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/07/30 21:43:02 INFO util.GSet: Computing capacity for map BlocksMap
20/07/30 21:43:02 INFO util.GSet: VM type       = 64-bit
20/07/30 21:43:02 INFO util.GSet: 2.0% max memory = 1.1 GB
20/07/30 21:43:02 INFO util.GSet: capacity      = 2^22 = 4194304 entries
20/07/30 21:43:02 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/07/30 21:43:02 INFO blockmanagement.BlockManager: defaultReplication         = 1
20/07/30 21:43:02 INFO blockmanagement.BlockManager: maxReplication             = 512
20/07/30 21:43:02 INFO blockmanagement.BlockManager: minReplication             = 1
20/07/30 21:43:02 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/07/30 21:43:02 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/07/30 21:43:02 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/07/30 21:43:02 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/07/30 21:43:02 INFO namenode.FSNamesystem: fsOwner             = jdbl (auth:SIMPLE)
20/07/30 21:43:02 INFO namenode.FSNamesystem: supergroup          = supergroup
20/07/30 21:43:02 INFO namenode.FSNamesystem: isPermissionEnabled = false
20/07/30 21:43:02 INFO namenode.FSNamesystem: HA Enabled: false
20/07/30 21:43:02 INFO namenode.FSNamesystem: Append Enabled: true
20/07/30 21:43:02 INFO util.GSet: Computing capacity for map INodeMap
20/07/30 21:43:02 INFO util.GSet: VM type       = 64-bit
20/07/30 21:43:02 INFO util.GSet: 1.0% max memory = 1.1 GB
20/07/30 21:43:02 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/07/30 21:43:02 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/07/30 21:43:02 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/07/30 21:43:02 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/07/30 21:43:02 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
20/07/30 21:43:02 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/07/30 21:43:02 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/07/30 21:43:02 INFO util.GSet: Computing capacity for map Namenode Retry Cache
20/07/30 21:43:02 INFO util.GSet: VM type       = 64-bit
20/07/30 21:43:02 INFO util.GSet: 0.029999999329447746% max memory = 1.1 GB
20/07/30 21:43:02 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/07/30 21:43:02 INFO common.Storage: Storage directory /tmp/beetest-test-705574401/BeetestCluster/name1 has been successfully formatted.
20/07/30 21:43:02 INFO common.Storage: Storage directory /tmp/beetest-test-705574401/BeetestCluster/name2 has been successfully formatted.
20/07/30 21:43:02 INFO namenode.FSImage: Saving image file /tmp/beetest-test-705574401/BeetestCluster/name1/current/fsimage.ckpt_0000000000000000000 using no compression
20/07/30 21:43:02 INFO namenode.FSImage: Saving image file /tmp/beetest-test-705574401/BeetestCluster/name2/current/fsimage.ckpt_0000000000000000000 using no compression
20/07/30 21:43:02 INFO namenode.FSImage: Image file /tmp/beetest-test-705574401/BeetestCluster/name2/current/fsimage.ckpt_0000000000000000000 of size 196 bytes saved in 0 seconds.
20/07/30 21:43:02 INFO namenode.FSImage: Image file /tmp/beetest-test-705574401/BeetestCluster/name1/current/fsimage.ckpt_0000000000000000000 of size 196 bytes saved in 0 seconds.
20/07/30 21:43:02 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
20/07/30 21:43:02 WARN impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
20/07/30 21:43:02 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
20/07/30 21:43:02 INFO impl.MetricsSystemImpl: NameNode metrics system started
20/07/30 21:43:03 INFO http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
20/07/30 21:43:03 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
20/07/30 21:43:03 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
20/07/30 21:43:03 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20/07/30 21:43:03 INFO http.HttpServer: dfs.webhdfs.enabled = false
20/07/30 21:43:03 INFO http.HttpServer: Jetty bound to port 46363
20/07/30 21:43:03 INFO mortbay.log: jetty-6.1.26
20/07/30 21:43:03 INFO mortbay.log: Extract jar:file:/home/jdbl/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0-tests.jar!/webapps/hdfs to /tmp/Jetty_localhost_46363_hdfs____13e49k/webapp
20/07/30 21:43:03 INFO mortbay.log: Started SelectChannelConnector@localhost:46363
20/07/30 21:43:03 INFO namenode.NameNode: Web-server up at: localhost:46363
20/07/30 21:43:03 INFO namenode.HostFileManager: read includes:
HostSet(
)
20/07/30 21:43:03 INFO namenode.HostFileManager: read excludes:
HostSet(
)
20/07/30 21:43:03 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
20/07/30 21:43:03 INFO util.GSet: Computing capacity for map BlocksMap
20/07/30 21:43:03 INFO util.GSet: VM type       = 64-bit
20/07/30 21:43:03 INFO util.GSet: 2.0% max memory = 1.1 GB
20/07/30 21:43:03 INFO util.GSet: capacity      = 2^22 = 4194304 entries
20/07/30 21:43:03 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
20/07/30 21:43:03 INFO blockmanagement.BlockManager: defaultReplication         = 1
20/07/30 21:43:03 INFO blockmanagement.BlockManager: maxReplication             = 512
20/07/30 21:43:03 INFO blockmanagement.BlockManager: minReplication             = 1
20/07/30 21:43:03 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
20/07/30 21:43:03 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false
20/07/30 21:43:03 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
20/07/30 21:43:03 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
20/07/30 21:43:03 INFO namenode.FSNamesystem: fsOwner             = jdbl (auth:SIMPLE)
20/07/30 21:43:03 INFO namenode.FSNamesystem: supergroup          = supergroup
20/07/30 21:43:03 INFO namenode.FSNamesystem: isPermissionEnabled = false
20/07/30 21:43:03 INFO namenode.FSNamesystem: HA Enabled: false
20/07/30 21:43:03 INFO namenode.FSNamesystem: Append Enabled: true
20/07/30 21:43:03 INFO util.GSet: Computing capacity for map INodeMap
20/07/30 21:43:03 INFO util.GSet: VM type       = 64-bit
20/07/30 21:43:03 INFO util.GSet: 1.0% max memory = 1.1 GB
20/07/30 21:43:03 INFO util.GSet: capacity      = 2^21 = 2097152 entries
20/07/30 21:43:03 INFO namenode.NameNode: Caching file names occuring more than 10 times
20/07/30 21:43:03 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
20/07/30 21:43:03 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
20/07/30 21:43:03 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 0
20/07/30 21:43:03 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
20/07/30 21:43:03 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
20/07/30 21:43:03 INFO util.GSet: Computing capacity for map Namenode Retry Cache
20/07/30 21:43:03 INFO util.GSet: VM type       = 64-bit
20/07/30 21:43:03 INFO util.GSet: 0.029999999329447746% max memory = 1.1 GB
20/07/30 21:43:03 INFO util.GSet: capacity      = 2^15 = 32768 entries
20/07/30 21:43:03 INFO common.Storage: Lock on /tmp/beetest-test-705574401/BeetestCluster/name1/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:43:03 INFO common.Storage: Lock on /tmp/beetest-test-705574401/BeetestCluster/name2/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:43:03 INFO namenode.FileJournalManager: Recovering unfinalized segments in /tmp/beetest-test-705574401/BeetestCluster/name1/current
20/07/30 21:43:03 INFO namenode.FileJournalManager: Recovering unfinalized segments in /tmp/beetest-test-705574401/BeetestCluster/name2/current
20/07/30 21:43:03 INFO namenode.FSImage: No edit log streams selected.
20/07/30 21:43:03 INFO namenode.FSImage: Loading image file /tmp/beetest-test-705574401/BeetestCluster/name1/current/fsimage_0000000000000000000 using no compression
20/07/30 21:43:03 INFO namenode.FSImage: Number of files = 1
20/07/30 21:43:03 INFO namenode.FSImage: Number of files under construction = 0
20/07/30 21:43:03 INFO namenode.FSImage: Image file /tmp/beetest-test-705574401/BeetestCluster/name1/current/fsimage_0000000000000000000 of size 196 bytes loaded in 0 seconds.
20/07/30 21:43:03 INFO namenode.FSImage: Loaded image for txid 0 from /tmp/beetest-test-705574401/BeetestCluster/name1/current/fsimage_0000000000000000000
20/07/30 21:43:03 INFO namenode.FSEditLog: Starting log segment at 1
20/07/30 21:43:03 INFO namenode.NameCache: initialized with 0 entries 0 lookups
20/07/30 21:43:03 INFO namenode.FSNamesystem: Finished loading FSImage in 101 msecs
20/07/30 21:43:03 INFO namenode.NameNode: RPC server is binding to localhost:0
20/07/30 21:43:03 INFO ipc.Server: Starting Socket Reader #1 for port 43831
20/07/30 21:43:03 INFO namenode.FSNamesystem: Registered FSNamesystemState MBean
20/07/30 21:43:03 INFO namenode.FSNamesystem: Number of blocks under construction: 0
20/07/30 21:43:03 INFO namenode.FSNamesystem: Number of blocks under construction: 0
20/07/30 21:43:03 INFO namenode.FSNamesystem: initializing replication queues
20/07/30 21:43:03 INFO blockmanagement.BlockManager: Total number of blocks            = 0
20/07/30 21:43:03 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0
20/07/30 21:43:03 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0
20/07/30 21:43:03 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0
20/07/30 21:43:03 INFO blockmanagement.BlockManager: Number of blocks being written    = 0
20/07/30 21:43:03 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
20/07/30 21:43:03 INFO hdfs.StateChange: STATE* Leaving safe mode after 0 secs
20/07/30 21:43:03 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
20/07/30 21:43:03 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
20/07/30 21:43:03 WARN util.MBeans: Failed to register MBean "Hadoop:service=NameNode,name=NameNodeInfo": Instance already exists.
20/07/30 21:43:03 INFO ipc.Server: IPC Server Responder: starting
20/07/30 21:43:03 INFO ipc.Server: IPC Server listener on 43831: starting
20/07/30 21:43:03 INFO namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:43831
20/07/30 21:43:03 INFO namenode.FSNamesystem: Starting services required for active state
20/07/30 21:43:03 INFO hdfs.MiniDFSCluster: Starting DataNode 0 with dfs.datanode.data.dir: file:/tmp/beetest-test-705574401/BeetestCluster/data/data1,file:/tmp/beetest-test-705574401/BeetestCluster/data/data2
20/07/30 21:43:03 INFO impl.MetricsSystemImpl: DataNode metrics system started (again)
20/07/30 21:43:03 INFO datanode.DataNode: Configured hostname is 127.0.0.1
20/07/30 21:43:03 WARN util.MBeans: Failed to register MBean "Hadoop:service=DataNode,name=DataNodeInfo": Instance already exists.
20/07/30 21:43:03 INFO datanode.DataNode: Opened streaming server at /127.0.0.1:33509
20/07/30 21:43:03 INFO datanode.DataNode: Balancing bandwith is 1048576 bytes/s
20/07/30 21:43:03 INFO http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer$QuotingInputFilter)
20/07/30 21:43:03 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
20/07/30 21:43:03 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
20/07/30 21:43:03 INFO http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
20/07/30 21:43:03 INFO datanode.DataNode: Opened info server at localhost:0
20/07/30 21:43:03 INFO datanode.DataNode: dfs.webhdfs.enabled = false
20/07/30 21:43:03 INFO http.HttpServer: Jetty bound to port 39541
20/07/30 21:43:03 INFO mortbay.log: jetty-6.1.26
20/07/30 21:43:03 INFO mortbay.log: Extract jar:file:/home/jdbl/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.2.0/hadoop-hdfs-2.2.0-tests.jar!/webapps/datanode to /tmp/Jetty_localhost_39541_datanode____14schf/webapp
20/07/30 21:43:03 INFO mortbay.log: Started SelectChannelConnector@localhost:39541
20/07/30 21:43:03 INFO datanode.DataNode: Opened IPC server at /127.0.0.1:33475
20/07/30 21:43:03 INFO datanode.DataNode: Refresh request received for nameservices: null
20/07/30 21:43:03 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>
20/07/30 21:43:03 INFO ipc.Server: Starting Socket Reader #1 for port 33475
20/07/30 21:43:03 INFO datanode.DataNode: Block pool <registering> (storage id unknown) service to localhost/127.0.0.1:43831 starting to offer service
20/07/30 21:43:03 INFO ipc.Server: IPC Server Responder: starting
20/07/30 21:43:03 INFO ipc.Server: IPC Server listener on 33475: starting
20/07/30 21:43:03 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:43:03 INFO common.Storage: Lock on /tmp/beetest-test-705574401/BeetestCluster/data/data1/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:43:03 INFO common.Storage: Storage directory /tmp/beetest-test-705574401/BeetestCluster/data/data1 is not formatted
20/07/30 21:43:03 INFO common.Storage: Formatting ...
20/07/30 21:43:03 INFO common.Storage: Lock on /tmp/beetest-test-705574401/BeetestCluster/data/data2/in_use.lock acquired by nodename 183@d3e4c9fd6693
20/07/30 21:43:03 INFO common.Storage: Storage directory /tmp/beetest-test-705574401/BeetestCluster/data/data2 is not formatted
20/07/30 21:43:03 INFO common.Storage: Formatting ...
20/07/30 21:43:03 INFO hdfs.MiniDFSCluster: Waiting for cluster to become active
20/07/30 21:43:03 INFO common.Storage: Locking is disabled
20/07/30 21:43:03 INFO common.Storage: Storage directory /tmp/beetest-test-705574401/BeetestCluster/data/data1/current/BP-2050360059-172.17.0.16-1596145382623 is not formatted.
20/07/30 21:43:03 INFO common.Storage: Formatting ...
20/07/30 21:43:03 INFO common.Storage: Formatting block pool BP-2050360059-172.17.0.16-1596145382623 directory /tmp/beetest-test-705574401/BeetestCluster/data/data1/current/BP-2050360059-172.17.0.16-1596145382623/current
20/07/30 21:43:03 INFO common.Storage: Locking is disabled
20/07/30 21:43:03 INFO common.Storage: Storage directory /tmp/beetest-test-705574401/BeetestCluster/data/data2/current/BP-2050360059-172.17.0.16-1596145382623 is not formatted.
20/07/30 21:43:03 INFO common.Storage: Formatting ...
20/07/30 21:43:03 INFO common.Storage: Formatting block pool BP-2050360059-172.17.0.16-1596145382623 directory /tmp/beetest-test-705574401/BeetestCluster/data/data2/current/BP-2050360059-172.17.0.16-1596145382623/current
20/07/30 21:43:03 INFO datanode.DataNode: Setting up storage: nsid=541270257;bpid=BP-2050360059-172.17.0.16-1596145382623;lv=-47;nsInfo=lv=-47;cid=testClusterID;nsid=541270257;c=0;bpid=BP-2050360059-172.17.0.16-1596145382623
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Added volume - /tmp/beetest-test-705574401/BeetestCluster/data/data1/current
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Added volume - /tmp/beetest-test-705574401/BeetestCluster/data/data2/current
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean
20/07/30 21:43:03 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1596155660681 with interval 21600000
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Adding block pool BP-2050360059-172.17.0.16-1596145382623
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Scanning block pool BP-2050360059-172.17.0.16-1596145382623 on volume /tmp/beetest-test-705574401/BeetestCluster/data/data1/current...
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Scanning block pool BP-2050360059-172.17.0.16-1596145382623 on volume /tmp/beetest-test-705574401/BeetestCluster/data/data2/current...
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-2050360059-172.17.0.16-1596145382623 on /tmp/beetest-test-705574401/BeetestCluster/data/data1/current: 13ms
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-2050360059-172.17.0.16-1596145382623 on /tmp/beetest-test-705574401/BeetestCluster/data/data2/current: 13ms
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-2050360059-172.17.0.16-1596145382623: 21ms
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-2050360059-172.17.0.16-1596145382623 on volume /tmp/beetest-test-705574401/BeetestCluster/data/data1/current...
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-2050360059-172.17.0.16-1596145382623 on volume /tmp/beetest-test-705574401/BeetestCluster/data/data1/current: 0ms
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-2050360059-172.17.0.16-1596145382623 on volume /tmp/beetest-test-705574401/BeetestCluster/data/data2/current...
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-2050360059-172.17.0.16-1596145382623 on volume /tmp/beetest-test-705574401/BeetestCluster/data/data2/current: 0ms
20/07/30 21:43:03 INFO impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
20/07/30 21:43:03 INFO datanode.DataNode: Block pool BP-2050360059-172.17.0.16-1596145382623 (storage id DS-1159781685-172.17.0.16-33509-1596145383549) service to localhost/127.0.0.1:43831 beginning handshake with NN
20/07/30 21:43:03 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1, storageID=DS-1159781685-172.17.0.16-33509-1596145383549, infoPort=39541, ipcPort=33475, storageInfo=lv=-47;cid=testClusterID;nsid=541270257;c=0) storage DS-1159781685-172.17.0.16-33509-1596145383549
20/07/30 21:43:03 INFO net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:33509
20/07/30 21:43:03 INFO datanode.DataNode: Block pool Block pool BP-2050360059-172.17.0.16-1596145382623 (storage id DS-1159781685-172.17.0.16-33509-1596145383549) service to localhost/127.0.0.1:43831 successfully registered with NN
20/07/30 21:43:03 INFO datanode.DataNode: For namenode localhost/127.0.0.1:43831 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec Initial delay: 0msec; heartBeatInterval=3000
20/07/30 21:43:03 INFO datanode.DataNode: Namenode Block pool BP-2050360059-172.17.0.16-1596145382623 (storage id DS-1159781685-172.17.0.16-33509-1596145383549) service to localhost/127.0.0.1:43831 trying to claim ACTIVE state with txid=1
20/07/30 21:43:03 INFO datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-2050360059-172.17.0.16-1596145382623 (storage id DS-1159781685-172.17.0.16-33509-1596145383549) service to localhost/127.0.0.1:43831
20/07/30 21:43:03 INFO blockmanagement.BlockManager: BLOCK* processReport: Received first block report from 127.0.0.1:33509 after starting up or becoming active. Its block contents are no longer considered stale
20/07/30 21:43:03 INFO BlockStateChange: BLOCK* processReport: from DatanodeRegistration(127.0.0.1, storageID=DS-1159781685-172.17.0.16-33509-1596145383549, infoPort=39541, ipcPort=33475, storageInfo=lv=-47;cid=testClusterID;nsid=541270257;c=0), blocks: 0, processing time: 0 msecs
20/07/30 21:43:03 INFO datanode.DataNode: BlockReport of 0 blocks took 0 msec to generate and 7 msecs for RPC and NN processing
20/07/30 21:43:03 INFO datanode.DataNode: sent block report, processed command:org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@195a5ccb
20/07/30 21:43:03 INFO util.GSet: Computing capacity for map BlockMap
20/07/30 21:43:03 INFO util.GSet: VM type       = 64-bit
20/07/30 21:43:03 INFO util.GSet: 0.5% max memory = 1.1 GB
20/07/30 21:43:03 INFO util.GSet: capacity      = 2^20 = 1048576 entries
20/07/30 21:43:03 INFO datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-2050360059-172.17.0.16-1596145382623
20/07/30 21:43:03 INFO datanode.DataBlockScanner: Added bpid=BP-2050360059-172.17.0.16-1596145382623 to blockPoolScannerMap, new size=1
20/07/30 21:43:03 INFO hdfs.MiniDFSCluster: Cluster is active
20/07/30 21:43:03 INFO hive.metastore: Mestastore configuration hive.metastore.warehouse.dir changed from hdfs://localhost:44047/tmp/beetest/warehouse to hdfs://localhost:43831/tmp/beetest/warehouse
20/07/30 21:43:03 INFO hive.metastore: Mestastore configuration javax.jdo.option.ConnectionURL changed from jdbc:derby:;databaseName=/tmp/MiniClusterTest-239445528/metastore_db;create=true to jdbc:derby:;databaseName=/tmp/beetest-test-705574401/metastore_db;create=true
20/07/30 21:43:03 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
20/07/30 21:43:03 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Shutting down the object store...	
20/07/30 21:43:03 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
20/07/30 21:43:03 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
20/07/30 21:43:03 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
20/07/30 21:43:03 INFO metastore.ObjectStore: ObjectStore, initialize called
20/07/30 21:43:03 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
20/07/30 21:43:03 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored
20/07/30 21:43:08 INFO metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
20/07/30 21:43:08 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:43:08 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:43:11 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:43:11 INFO DataNucleus.Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
20/07/30 21:43:11 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/07/30 21:43:11 INFO metastore.ObjectStore: Initialized ObjectStore
20/07/30 21:43:11 WARN metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException
20/07/30 21:43:11 INFO metastore.HiveMetaStore: Added admin role in metastore
20/07/30 21:43:12 INFO metastore.HiveMetaStore: Added public role in metastore
20/07/30 21:43:12 INFO metastore.HiveMetaStore: No user is added in admin role, since config is empty
20/07/30 21:43:12 INFO session.SessionState: Created HDFS directory: hdfs://localhost:43831/tmp/beetest/scratchdir/jdbl
20/07/30 21:43:12 INFO session.SessionState: Created local directory: /tmp/beetest-test-705574401/localScratchDir
20/07/30 21:43:12 INFO session.SessionState: Created local directory: /tmp/b08c0b59-44da-42df-b8af-01c839cfc621_resources
20/07/30 21:43:12 INFO session.SessionState: Created HDFS directory: hdfs://localhost:43831/tmp/beetest/scratchdir/jdbl/b08c0b59-44da-42df-b8af-01c839cfc621
20/07/30 21:43:12 INFO session.SessionState: Created local directory: /tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621
20/07/30 21:43:12 INFO session.SessionState: Created HDFS directory: hdfs://localhost:43831/tmp/beetest/scratchdir/jdbl/b08c0b59-44da-42df-b8af-01c839cfc621/_tmp_space.db
20/07/30 21:43:12 INFO service.CompositeService: Operation log root directory is created: /tmp/jdbl/operation_logs
20/07/30 21:43:12 INFO service.CompositeService: HiveServer2: Background operation thread pool size: 100
20/07/30 21:43:12 INFO service.CompositeService: HiveServer2: Background operation thread wait queue size: 100
20/07/30 21:43:12 INFO service.CompositeService: HiveServer2: Background operation thread keepalive time: 10 seconds
20/07/30 21:43:12 INFO service.AbstractService: Service:OperationManager is inited.
20/07/30 21:43:12 INFO service.AbstractService: Service:SessionManager is inited.
20/07/30 21:43:12 INFO service.AbstractService: Service:CLIService is inited.
20/07/30 21:43:12 INFO service.AbstractService: Service:ThriftBinaryCLIService is inited.
20/07/30 21:43:12 INFO service.AbstractService: Service:HiveServer2 is inited.
20/07/30 21:43:12 INFO service.AbstractService: Service:OperationManager is started.
20/07/30 21:43:12 INFO service.AbstractService: Service:SessionManager is started.
20/07/30 21:43:12 INFO service.AbstractService: Service:CLIService is started.
20/07/30 21:43:12 INFO metastore.ObjectStore: ObjectStore, initialize called
20/07/30 21:43:12 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
20/07/30 21:43:12 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/07/30 21:43:12 INFO metastore.ObjectStore: Initialized ObjectStore
20/07/30 21:43:12 INFO metastore.HiveMetaStore: 0: get_databases: default
20/07/30 21:43:12 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_databases: default	
20/07/30 21:43:12 INFO metastore.HiveMetaStore: 0: Shutting down the object store...
20/07/30 21:43:12 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Shutting down the object store...	
20/07/30 21:43:12 INFO metastore.HiveMetaStore: 0: Metastore shutdown complete.
20/07/30 21:43:12 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=Metastore shutdown complete.	
20/07/30 21:43:12 INFO service.AbstractService: Service:ThriftBinaryCLIService is started.
20/07/30 21:43:12 INFO service.AbstractService: Service:HiveServer2 is started.
20/07/30 21:43:12 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
20/07/30 21:43:12 INFO thrift.ThriftCLIService: Starting ThriftBinaryCLIService on port 46117 with 5...500 worker threads
Jul 30, 2020 9:43:12 PM com.spotify.beetest.TestQueryExecutor run
INFO: Generated query filename: /tmp/beetest-test-705574401-query.hql
Jul 30, 2020 9:43:12 PM com.spotify.beetest.TestQueryExecutor run
INFO: Generated query content: 
CREATE DATABASE IF NOT EXISTS beetest;
USE beetest;
DROP TABLE IF EXISTS ${table};

CREATE TABLE ${table}(artist STRING, song STRING, user STRING, ts TIMESTAMP)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH 'src/test/resources/artist-count/input.tsv' INTO TABLE ${table};
DROP TABLE IF EXISTS output_705574401;
CREATE TABLE output_705574401
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY '\t'
COLLECTION ITEMS TERMINATED BY '|'
MAP KEYS TERMINATED BY '$'
LOCATION '/tmp/beetest-test-705574401-output_705574401' AS 
SELECT artist, COUNT(*) AS cnt
FROM ${table}
GROUP BY artist
ORDER BY cnt DESC
LIMIT 2;

Jul 30, 2020 9:43:12 PM com.spotify.beetest.TestQueryExecutor getTestCaseCommand
INFO: CONFIG BEING USED IS: /tmp/beetest-test-705574401/MiniDFSClusterConfig/local-config
20/07/30 21:43:12 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:12 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:12 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:12 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:12 INFO parse.ParseDriver: Parsing command: CREATE DATABASE IF NOT EXISTS beetest
java.lang.instrument.IllegalClassFormatException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA5.
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:94)
	at sun.instrument.TransformerManager.transform(TransformerManager.java:188)
	at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:428)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.<init>(HiveParser_IdentifiersParser.java:12374)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:706)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:700)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:195)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:396)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)
	at com.spotify.beetest.TestQueryExecutor.executeHiveQuery(TestQueryExecutor.java:178)
	at com.spotify.beetest.TestQueryExecutor.run(TestQueryExecutor.java:72)
	at com.spotify.beetest.TestHiveServer2.testHiveQuery(TestHiveServer2.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)
Caused by: java.io.IOException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA5.
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrumentError(Instrumenter.java:159)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:109)
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:92)
	... 54 more
Caused by: org.jacoco.agent.rt.internal_43f5073.asm.MethodTooLargeException: Method too large: org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA5.specialStateTransition (ILorg/antlr/runtime/IntStream;)I
	at org.jacoco.agent.rt.internal_43f5073.asm.MethodWriter.computeMethodInfoSize(MethodWriter.java:2087)
	at org.jacoco.agent.rt.internal_43f5073.asm.ClassWriter.toByteArray(ClassWriter.java:447)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:90)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:107)
	... 55 more
java.lang.instrument.IllegalClassFormatException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA13.
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:94)
	at sun.instrument.TransformerManager.transform(TransformerManager.java:188)
	at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:428)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.<init>(HiveParser_IdentifiersParser.java:12375)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:706)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:700)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:195)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:396)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)
	at com.spotify.beetest.TestQueryExecutor.executeHiveQuery(TestQueryExecutor.java:178)
	at com.spotify.beetest.TestQueryExecutor.run(TestQueryExecutor.java:72)
	at com.spotify.beetest.TestHiveServer2.testHiveQuery(TestHiveServer2.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)
Caused by: java.io.IOException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA13.
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrumentError(Instrumenter.java:159)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:109)
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:92)
	... 54 more
Caused by: org.jacoco.agent.rt.internal_43f5073.asm.MethodTooLargeException: Method too large: org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA13.specialStateTransition (ILorg/antlr/runtime/IntStream;)I
	at org.jacoco.agent.rt.internal_43f5073.asm.MethodWriter.computeMethodInfoSize(MethodWriter.java:2087)
	at org.jacoco.agent.rt.internal_43f5073.asm.ClassWriter.toByteArray(ClassWriter.java:447)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:90)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:107)
	... 55 more
java.lang.instrument.IllegalClassFormatException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA14.
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:94)
	at sun.instrument.TransformerManager.transform(TransformerManager.java:188)
	at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:428)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.<init>(HiveParser_IdentifiersParser.java:12376)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:706)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:700)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:195)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:396)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)
	at com.spotify.beetest.TestQueryExecutor.executeHiveQuery(TestQueryExecutor.java:178)
	at com.spotify.beetest.TestQueryExecutor.run(TestQueryExecutor.java:72)
	at com.spotify.beetest.TestHiveServer2.testHiveQuery(TestHiveServer2.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)
Caused by: java.io.IOException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA14.
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrumentError(Instrumenter.java:159)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:109)
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:92)
	... 54 more
Caused by: org.jacoco.agent.rt.internal_43f5073.asm.MethodTooLargeException: Method too large: org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA14.specialStateTransition (ILorg/antlr/runtime/IntStream;)I
	at org.jacoco.agent.rt.internal_43f5073.asm.MethodWriter.computeMethodInfoSize(MethodWriter.java:2087)
	at org.jacoco.agent.rt.internal_43f5073.asm.ClassWriter.toByteArray(ClassWriter.java:447)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:90)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:107)
	... 55 more
java.lang.instrument.IllegalClassFormatException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA15.
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:94)
	at sun.instrument.TransformerManager.transform(TransformerManager.java:188)
	at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:428)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.<init>(HiveParser_IdentifiersParser.java:12377)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:706)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:700)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:195)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:396)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)
	at com.spotify.beetest.TestQueryExecutor.executeHiveQuery(TestQueryExecutor.java:178)
	at com.spotify.beetest.TestQueryExecutor.run(TestQueryExecutor.java:72)
	at com.spotify.beetest.TestHiveServer2.testHiveQuery(TestHiveServer2.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)
Caused by: java.io.IOException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA15.
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrumentError(Instrumenter.java:159)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:109)
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:92)
	... 54 more
Caused by: org.jacoco.agent.rt.internal_43f5073.asm.MethodTooLargeException: Method too large: org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA15.specialStateTransition (ILorg/antlr/runtime/IntStream;)I
	at org.jacoco.agent.rt.internal_43f5073.asm.MethodWriter.computeMethodInfoSize(MethodWriter.java:2087)
	at org.jacoco.agent.rt.internal_43f5073.asm.ClassWriter.toByteArray(ClassWriter.java:447)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:90)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:107)
	... 55 more
java.lang.instrument.IllegalClassFormatException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA16.
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:94)
	at sun.instrument.TransformerManager.transform(TransformerManager.java:188)
	at sun.instrument.InstrumentationImpl.transform(InstrumentationImpl.java:428)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at org.apache.hadoop.hive.ql.parse.HiveParser_IdentifiersParser.<init>(HiveParser_IdentifiersParser.java:12378)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:706)
	at org.apache.hadoop.hive.ql.parse.HiveParser.<init>(HiveParser.java:700)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:195)
	at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:166)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:396)
	at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:308)
	at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1122)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1170)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1059)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1049)
	at com.spotify.beetest.TestQueryExecutor.executeHiveQuery(TestQueryExecutor.java:178)
	at com.spotify.beetest.TestQueryExecutor.run(TestQueryExecutor.java:72)
	at com.spotify.beetest.TestHiveServer2.testHiveQuery(TestHiveServer2.java:50)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:45)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:42)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:30)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:263)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:68)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:47)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:231)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:60)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:50)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:222)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:300)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:367)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:274)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:161)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:290)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:242)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:121)
Caused by: java.io.IOException: Error while instrumenting org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA16.
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrumentError(Instrumenter.java:159)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:109)
	at org.jacoco.agent.rt.internal_43f5073.CoverageTransformer.transform(CoverageTransformer.java:92)
	... 54 more
Caused by: org.jacoco.agent.rt.internal_43f5073.asm.MethodTooLargeException: Method too large: org/apache/hadoop/hive/ql/parse/HiveParser_IdentifiersParser$DFA16.specialStateTransition (ILorg/antlr/runtime/IntStream;)I
	at org.jacoco.agent.rt.internal_43f5073.asm.MethodWriter.computeMethodInfoSize(MethodWriter.java:2087)
	at org.jacoco.agent.rt.internal_43f5073.asm.ClassWriter.toByteArray(ClassWriter.java:447)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:90)
	at org.jacoco.agent.rt.internal_43f5073.core.instr.Instrumenter.instrument(Instrumenter.java:107)
	... 55 more
20/07/30 21:43:15 INFO parse.ParseDriver: Parse Completed
20/07/30 21:43:15 INFO log.PerfLogger: </PERFLOG method=parse start=1596145392972 end=1596145395410 duration=2438 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:15 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:15 INFO ql.Driver: Semantic Analysis Completed
20/07/30 21:43:15 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1596145395417 end=1596145395517 duration=100 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:15 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
20/07/30 21:43:15 INFO log.PerfLogger: </PERFLOG method=compile start=1596145392459 end=1596145395530 duration=3071 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:15 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
20/07/30 21:43:15 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:15 INFO ql.Driver: Starting command(queryId=jdbl_20200730214312_f51fe5e5-9735-4da2-8865-92737c880f0d): CREATE DATABASE IF NOT EXISTS beetest
20/07/30 21:43:15 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1596145392459 end=1596145395534 duration=3075 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:15 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:15 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:15 INFO ql.Driver: Starting task [Stage-0:DDL] in serial mode
20/07/30 21:43:15 INFO metastore.HiveMetaStore: 0: create_database: Database(name:beetest, description:null, locationUri:hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db, parameters:null, ownerName:jdbl, ownerType:USER)
20/07/30 21:43:15 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=create_database: Database(name:beetest, description:null, locationUri:hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db, parameters:null, ownerName:jdbl, ownerType:USER)	
20/07/30 21:43:15 INFO metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
20/07/30 21:43:15 INFO metastore.ObjectStore: ObjectStore, initialize called
20/07/30 21:43:15 INFO DataNucleus.Query: Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
20/07/30 21:43:15 INFO metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
20/07/30 21:43:15 INFO metastore.ObjectStore: Initialized ObjectStore
20/07/30 21:43:15 WARN metastore.ObjectStore: Failed to get database beetest, returning NoSuchObjectException
20/07/30 21:43:15 INFO common.FileUtils: Creating directory if it doesn't exist: hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=runTasks start=1596145395534 end=1596145396110 duration=576 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1596145395530 end=1596145396110 duration=580 from=org.apache.hadoop.hive.ql.Driver>
OK
20/07/30 21:43:16 INFO ql.Driver: OK
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1596145396111 end=1596145396111 duration=0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1596145392459 end=1596145396111 duration=3652 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO parse.ParseDriver: Parsing command: USE beetest
20/07/30 21:43:16 INFO parse.ParseDriver: Parse Completed
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=parse start=1596145396112 end=1596145396113 duration=1 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO metastore.HiveMetaStore: 0: get_database: beetest
20/07/30 21:43:16 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_database: beetest	
20/07/30 21:43:16 INFO ql.Driver: Semantic Analysis Completed
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1596145396113 end=1596145396129 duration=16 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=compile start=1596145396112 end=1596145396129 duration=17 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Starting command(queryId=jdbl_20200730214316_f3da298b-f4b2-4332-a686-149b8d360d3c): USE beetest
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1596145396112 end=1596145396130 duration=18 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Starting task [Stage-0:DDL] in serial mode
20/07/30 21:43:16 INFO metastore.HiveMetaStore: 0: get_database: beetest
20/07/30 21:43:16 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_database: beetest	
20/07/30 21:43:16 INFO metastore.HiveMetaStore: 0: get_database: beetest
20/07/30 21:43:16 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_database: beetest	
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=runTasks start=1596145396130 end=1596145396134 duration=4 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1596145396130 end=1596145396134 duration=4 from=org.apache.hadoop.hive.ql.Driver>
OK
20/07/30 21:43:16 INFO ql.Driver: OK
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1596145396134 end=1596145396134 duration=0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1596145396112 end=1596145396134 duration=22 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO parse.ParseDriver: Parsing command: DROP TABLE IF EXISTS stream
20/07/30 21:43:16 INFO parse.ParseDriver: Parse Completed
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=parse start=1596145396134 end=1596145396137 duration=3 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:16 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:16 INFO ql.Driver: Semantic Analysis Completed
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1596145396137 end=1596145396454 duration=317 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=compile start=1596145396134 end=1596145396454 duration=320 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Starting command(queryId=jdbl_20200730214316_85070d5f-abfa-4ea3-adad-1cdacef60dda): DROP TABLE IF EXISTS stream
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1596145396134 end=1596145396454 duration=320 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Starting task [Stage-0:DDL] in serial mode
20/07/30 21:43:16 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:16 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:16 ERROR metadata.Hive: Table stream not found: beetest.stream table not found
20/07/30 21:43:16 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:16 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=runTasks start=1596145396454 end=1596145396472 duration=18 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1596145396454 end=1596145396473 duration=19 from=org.apache.hadoop.hive.ql.Driver>
OK
20/07/30 21:43:16 INFO ql.Driver: OK
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1596145396473 end=1596145396473 duration=0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1596145396134 end=1596145396473 duration=339 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO parse.ParseDriver: Parsing command: CREATE TABLE stream(artist STRING, song STRING, user STRING, ts TIMESTAMP) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE
20/07/30 21:43:16 INFO parse.ParseDriver: Parse Completed
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=parse start=1596145396473 end=1596145396480 duration=7 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO parse.CalcitePlanner: Starting Semantic Analysis
20/07/30 21:43:16 INFO parse.CalcitePlanner: Creating table beetest.stream position=13
20/07/30 21:43:16 INFO metastore.HiveMetaStore: 0: get_database: beetest
20/07/30 21:43:16 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_database: beetest	
20/07/30 21:43:16 INFO ql.Driver: Semantic Analysis Completed
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1596145396480 end=1596145396548 duration=68 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=compile start=1596145396473 end=1596145396548 duration=75 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Starting command(queryId=jdbl_20200730214316_b9c4dbd2-ecbf-4a42-bdc2-8466ef519598): CREATE TABLE stream(artist STRING, song STRING, user STRING, ts TIMESTAMP) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' STORED AS TEXTFILE
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1596145396473 end=1596145396550 duration=77 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO ql.Driver: Starting task [Stage-0:DDL] in serial mode
20/07/30 21:43:16 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:stream, dbName:beetest, owner:jdbl, createTime:1596145396, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:artist, type:string, comment:null), FieldSchema(name:song, type:string, comment:null), FieldSchema(name:user, type:string, comment:null), FieldSchema(name:ts, type:timestamp, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{field.delim=	, serialization.format=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
20/07/30 21:43:16 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=create_table: Table(tableName:stream, dbName:beetest, owner:jdbl, createTime:1596145396, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:artist, type:string, comment:null), FieldSchema(name:song, type:string, comment:null), FieldSchema(name:user, type:string, comment:null), FieldSchema(name:ts, type:timestamp, comment:null)], location:null, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{field.delim=	, serialization.format=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
20/07/30 21:43:16 INFO common.FileUtils: Creating directory if it doesn't exist: hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/stream
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=runTasks start=1596145396550 end=1596145396997 duration=447 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1596145396548 end=1596145396997 duration=449 from=org.apache.hadoop.hive.ql.Driver>
OK
20/07/30 21:43:16 INFO ql.Driver: OK
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1596145396997 end=1596145396997 duration=0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1596145396473 end=1596145396997 duration=524 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:16 INFO parse.ParseDriver: Parsing command: LOAD DATA LOCAL INPATH 'src/test/resources/artist-count/input.tsv' INTO TABLE stream
20/07/30 21:43:17 INFO parse.ParseDriver: Parse Completed
20/07/30 21:43:17 INFO log.PerfLogger: </PERFLOG method=parse start=1596145396998 end=1596145397000 duration=2 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:17 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:17 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:17 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:17 INFO ql.Driver: Semantic Analysis Completed
20/07/30 21:43:17 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1596145397000 end=1596145397459 duration=459 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:17 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
20/07/30 21:43:17 INFO log.PerfLogger: </PERFLOG method=compile start=1596145396998 end=1596145397460 duration=462 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:17 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
20/07/30 21:43:17 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:17 INFO ql.Driver: Starting command(queryId=jdbl_20200730214316_74a68820-2ac8-4683-86c4-92aa21f94834): LOAD DATA LOCAL INPATH 'src/test/resources/artist-count/input.tsv' INTO TABLE stream
20/07/30 21:43:17 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1596145396998 end=1596145397460 duration=462 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:17 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:17 INFO log.PerfLogger: <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:17 INFO ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Loading data to table beetest.stream
20/07/30 21:43:17 INFO exec.Task: Loading data to table beetest.stream from file:/tmp/tmpu74hqnl2/Beetest/src/test/resources/artist-count/input.tsv
20/07/30 21:43:17 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:17 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:17 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:17 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:18 INFO hdfs.StateChange: BLOCK* allocateBlock: /tmp/beetest/warehouse/beetest.db/stream/input.tsv. BP-2050360059-172.17.0.16-1596145382623 blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:33509|RBW]]}
20/07/30 21:43:18 INFO datanode.DataNode: Receiving BP-2050360059-172.17.0.16-1596145382623:blk_1073741825_1001 src: /127.0.0.1:56170 dest: /127.0.0.1:33509
20/07/30 21:43:18 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33509 is added to blk_1073741825_1001{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:33509|RBW]]} size 0
20/07/30 21:43:18 INFO DataNode.clienttrace: src: /127.0.0.1:56170, dest: /127.0.0.1:33509, bytes: 296, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1177678987_1, offset: 0, srvID: DS-1159781685-172.17.0.16-33509-1596145383549, blockid: BP-2050360059-172.17.0.16-1596145382623:blk_1073741825_1001, duration: 40424179
20/07/30 21:43:18 INFO datanode.DataNode: PacketResponder: BP-2050360059-172.17.0.16-1596145382623:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
20/07/30 21:43:18 INFO hdfs.StateChange: DIR* completeFile: /tmp/beetest/warehouse/beetest.db/stream/input.tsv is closed by DFSClient_NONMAPREDUCE_1177678987_1
20/07/30 21:43:18 INFO metadata.Hive: Renaming src: file:/tmp/tmpu74hqnl2/Beetest/src/test/resources/artist-count/input.tsv, dest: hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/stream/input.tsv, Status:true
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: alter_table: db=beetest tbl=stream newtbl=stream
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=alter_table: db=beetest tbl=stream newtbl=stream	
20/07/30 21:43:18 INFO hive.log: Updating table stats fast for stream
20/07/30 21:43:18 INFO hive.log: Updated size of table stream to 296
20/07/30 21:43:18 INFO datanode.BlockPoolSliceScanner: Verification succeeded for BP-2050360059-172.17.0.16-1596145382623:blk_1073741825_1001
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=task.STATS.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO ql.Driver: Starting task [Stage-1:STATS] in serial mode
20/07/30 21:43:18 INFO exec.StatsTask: Executing stats task
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: alter_table: db=beetest tbl=stream newtbl=stream
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=alter_table: db=beetest tbl=stream newtbl=stream	
20/07/30 21:43:18 INFO hive.log: Updating table stats fast for stream
20/07/30 21:43:18 INFO hive.log: Updated size of table stream to 296
Table beetest.stream stats: [numFiles=1, totalSize=296]
20/07/30 21:43:18 INFO exec.Task: Table beetest.stream stats: [numFiles=1, totalSize=296]
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=runTasks start=1596145397460 end=1596145398923 duration=1463 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1596145397460 end=1596145398923 duration=1463 from=org.apache.hadoop.hive.ql.Driver>
OK
20/07/30 21:43:18 INFO ql.Driver: OK
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1596145398923 end=1596145398923 duration=0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1596145396998 end=1596145398923 duration=1925 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO parse.ParseDriver: Parsing command: DROP TABLE IF EXISTS output_705574401
20/07/30 21:43:18 INFO parse.ParseDriver: Parse Completed
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=parse start=1596145398923 end=1596145398924 duration=1 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=output_705574401
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=output_705574401	
20/07/30 21:43:18 INFO ql.Driver: Semantic Analysis Completed
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1596145398924 end=1596145398933 duration=9 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:null, properties:null)
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=compile start=1596145398923 end=1596145398933 duration=10 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO ql.Driver: Starting command(queryId=jdbl_20200730214318_4cb84224-d260-4196-8883-de104425f4fe): DROP TABLE IF EXISTS output_705574401
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1596145398923 end=1596145398934 duration=11 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO ql.Driver: Starting task [Stage-0:DDL] in serial mode
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=output_705574401
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=output_705574401	
20/07/30 21:43:18 ERROR metadata.Hive: Table output_705574401 not found: beetest.output_705574401 table not found
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=output_705574401
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=output_705574401	
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=runTasks start=1596145398934 end=1596145398938 duration=4 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1596145398933 end=1596145398938 duration=5 from=org.apache.hadoop.hive.ql.Driver>
OK
20/07/30 21:43:18 INFO ql.Driver: OK
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1596145398938 end=1596145398938 duration=0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1596145398923 end=1596145398938 duration=15 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=compile from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=parse from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO parse.ParseDriver: Parsing command: CREATE TABLE output_705574401 ROW FORMAT DELIMITED  FIELDS TERMINATED BY '\t' COLLECTION ITEMS TERMINATED BY '|' MAP KEYS TERMINATED BY '$' LOCATION '/tmp/beetest-test-705574401-output_705574401' AS  SELECT artist, COUNT(*) AS cnt FROM stream GROUP BY artist ORDER BY cnt DESC LIMIT 2
20/07/30 21:43:18 INFO parse.ParseDriver: Parse Completed
20/07/30 21:43:18 INFO log.PerfLogger: </PERFLOG method=parse start=1596145398939 end=1596145398968 duration=29 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO log.PerfLogger: <PERFLOG method=semanticAnalyze from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:18 INFO parse.CalcitePlanner: Starting Semantic Analysis
20/07/30 21:43:18 INFO parse.CalcitePlanner: Creating table beetest.output_705574401 position=13
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_database: beetest
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_database: beetest	
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=output_705574401
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=output_705574401	
20/07/30 21:43:18 INFO parse.CalcitePlanner: Completed phase 1 of Semantic Analysis
20/07/30 21:43:18 INFO parse.CalcitePlanner: Get metadata for source tables
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=stream
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=stream	
20/07/30 21:43:18 INFO parse.CalcitePlanner: Get metadata for subqueries
20/07/30 21:43:18 INFO parse.CalcitePlanner: Get metadata for destination tables
20/07/30 21:43:18 INFO metastore.HiveMetaStore: 0: get_database: beetest
20/07/30 21:43:18 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_database: beetest	
20/07/30 21:43:18 INFO common.FileUtils: Creating directory if it doesn't exist: hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1
20/07/30 21:43:19 INFO parse.CalcitePlanner: Completed getting MetaData in Semantic Analysis
20/07/30 21:43:19 INFO parse.BaseSemanticAnalyzer: Not invoking CBO because the statement has too few joins
20/07/30 21:43:19 INFO parse.CalcitePlanner: Set stats collection dir : hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10002
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for FS(9)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for LIM(8)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for SEL(7)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for RS(6)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for SEL(5)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for GBY(4)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for RS(3)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for GBY(2)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for SEL(1)
20/07/30 21:43:19 INFO ppd.OpProcFactory: Processing for TS(0)
20/07/30 21:43:19 INFO optimizer.ColumnPrunerProcFactory: RS 6 oldColExprMap: {VALUE._col0=Column[_col0], KEY.reducesinkkey0=Column[_col1]}
20/07/30 21:43:19 INFO optimizer.ColumnPrunerProcFactory: RS 6 newColExprMap: {VALUE._col0=Column[_col0], KEY.reducesinkkey0=Column[_col1]}
20/07/30 21:43:19 INFO optimizer.ColumnPrunerProcFactory: RS 3 oldColExprMap: {KEY._col0=Column[_col0], VALUE._col0=Column[_col1]}
20/07/30 21:43:19 INFO optimizer.ColumnPrunerProcFactory: RS 3 newColExprMap: {KEY._col0=Column[_col0], VALUE._col0=Column[_col1]}
20/07/30 21:43:19 INFO log.PerfLogger: <PERFLOG method=partition-retrieving from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
20/07/30 21:43:19 INFO log.PerfLogger: </PERFLOG method=partition-retrieving start=1596145399406 end=1596145399407 duration=1 from=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionPruner>
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Found 0 null table scans
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Found 0 null table scans
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Found 0 null table scans
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Found 0 null table scans
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Found 0 null table scans
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Looking for table scans where optimization is applicable
20/07/30 21:43:19 INFO physical.NullScanTaskDispatcher: Found 0 null table scans
20/07/30 21:43:19 INFO parse.CalcitePlanner: Completed plan generation
20/07/30 21:43:19 INFO ql.Driver: Semantic Analysis Completed
20/07/30 21:43:19 INFO log.PerfLogger: </PERFLOG method=semanticAnalyze start=1596145398968 end=1596145399449 duration=481 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:19 INFO ql.Driver: Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:artist, type:string, comment:null), FieldSchema(name:cnt, type:bigint, comment:null)], properties:null)
20/07/30 21:43:19 INFO log.PerfLogger: </PERFLOG method=compile start=1596145398938 end=1596145399449 duration=511 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:19 INFO ql.Driver: Concurrency mode is disabled, not creating a lock manager
20/07/30 21:43:19 INFO log.PerfLogger: <PERFLOG method=Driver.execute from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:19 INFO ql.Driver: Starting command(queryId=jdbl_20200730214318_bb1f5913-c5a4-4469-b834-3da8862d06c2): CREATE TABLE output_705574401 ROW FORMAT DELIMITED  FIELDS TERMINATED BY '\t' COLLECTION ITEMS TERMINATED BY '|' MAP KEYS TERMINATED BY '$' LOCATION '/tmp/beetest-test-705574401-output_705574401' AS  SELECT artist, COUNT(*) AS cnt FROM stream GROUP BY artist ORDER BY cnt DESC LIMIT 2
Query ID = jdbl_20200730214318_bb1f5913-c5a4-4469-b834-3da8862d06c2
20/07/30 21:43:19 INFO ql.Driver: Query ID = jdbl_20200730214318_bb1f5913-c5a4-4469-b834-3da8862d06c2
Total jobs = 2
20/07/30 21:43:19 INFO ql.Driver: Total jobs = 2
20/07/30 21:43:19 INFO log.PerfLogger: </PERFLOG method=TimeToSubmit start=1596145398938 end=1596145399450 duration=512 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:19 INFO log.PerfLogger: <PERFLOG method=runTasks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:19 INFO log.PerfLogger: <PERFLOG method=task.MAPRED.Stage-1 from=org.apache.hadoop.hive.ql.Driver>
Launching Job 1 out of 2
20/07/30 21:43:19 INFO ql.Driver: Launching Job 1 out of 2
20/07/30 21:43:19 INFO ql.Driver: Starting task [Stage-1:MAPRED] in parallel
20/07/30 21:43:19 INFO log.PerfLogger: <PERFLOG method=getInputSummary from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:19 INFO exec.Utilities: Cache Content Summary for hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/stream length: 296 file count: 1 directory count: 1
20/07/30 21:43:19 INFO log.PerfLogger: </PERFLOG method=getInputSummary start=1596145399518 end=1596145399566 duration=48 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:19 INFO exec.Utilities: BytesPerReducer=256000000 maxReducers=1009 totalInputFileSize=296
Number of reduce tasks not specified. Estimated from input data size: 1
20/07/30 21:43:19 INFO exec.Task: Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
20/07/30 21:43:19 INFO exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
20/07/30 21:43:19 INFO exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
20/07/30 21:43:19 INFO exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
20/07/30 21:43:19 INFO exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
20/07/30 21:43:19 INFO exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
20/07/30 21:43:19 INFO exec.Task:   set mapreduce.job.reduces=<number>
20/07/30 21:43:19 INFO mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
20/07/30 21:43:19 INFO exec.Utilities: Processing alias stream
20/07/30 21:43:19 INFO exec.Utilities: Adding input file hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/stream
20/07/30 21:43:19 INFO exec.Utilities: Content Summary hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/streamlength: 296 num files: 1 num directories: 1
20/07/30 21:43:19 INFO log.PerfLogger: <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:19 INFO exec.Utilities: Serializing MapWork via kryo
20/07/30 21:43:19 INFO log.PerfLogger: </PERFLOG method=serializePlan start=1596145399613 end=1596145399774 duration=161 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:19 INFO log.PerfLogger: <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:19 INFO exec.Utilities: Serializing ReduceWork via kryo
20/07/30 21:43:19 INFO log.PerfLogger: </PERFLOG method=serializePlan start=1596145399783 end=1596145399795 duration=12 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:19 ERROR mr.ExecDriver: local
20/07/30 21:43:19 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
20/07/30 21:43:19 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
20/07/30 21:43:19 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
20/07/30 21:43:19 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/map.xml
20/07/30 21:43:19 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/reduce.xml
20/07/30 21:43:19 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
20/07/30 21:43:20 INFO log.PerfLogger: <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
20/07/30 21:43:20 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/map.xml
20/07/30 21:43:20 INFO io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
20/07/30 21:43:20 INFO io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/stream; using filter path hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/stream
20/07/30 21:43:20 INFO input.FileInputFormat: Total input paths to process : 1
20/07/30 21:43:20 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
20/07/30 21:43:20 INFO io.CombineHiveInputFormat: number of splits 1
20/07/30 21:43:20 INFO io.CombineHiveInputFormat: Number of all splits 1
20/07/30 21:43:20 INFO log.PerfLogger: </PERFLOG method=getSplits start=1596145400044 end=1596145400096 duration=52 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
20/07/30 21:43:20 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.mapoutput.value.class is deprecated. Instead, use mapreduce.map.output.value.class
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.mapoutput.key.class is deprecated. Instead, use mapreduce.map.output.key.class
20/07/30 21:43:20 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
20/07/30 21:43:20 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
20/07/30 21:43:20 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1487730247_0001
20/07/30 21:43:20 WARN conf.Configuration: file:/tmp/hadoop-jdbl/mapred/staging/jdbl1487730247/.staging/job_local1487730247_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
20/07/30 21:43:20 WARN conf.Configuration: file:/tmp/hadoop-jdbl/mapred/staging/jdbl1487730247/.staging/job_local1487730247_0001/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
20/07/30 21:43:20 WARN conf.Configuration: file:/tmp/hadoop-jdbl/mapred/local/localRunner/jdbl/job_local1487730247_0001/job_local1487730247_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
20/07/30 21:43:20 WARN conf.Configuration: file:/tmp/hadoop-jdbl/mapred/local/localRunner/jdbl/job_local1487730247_0001/job_local1487730247_0001.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
20/07/30 21:43:20 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
20/07/30 21:43:20 INFO mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
Job running in-process (local Hadoop)
20/07/30 21:43:20 INFO exec.Task: Job running in-process (local Hadoop)
20/07/30 21:43:20 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
20/07/30 21:43:20 INFO mapred.LocalJobRunner: Waiting for map tasks
20/07/30 21:43:20 INFO mapred.LocalJobRunner: Starting task: attempt_local1487730247_0001_m_000000_0
20/07/30 21:43:20 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/07/30 21:43:20 INFO mapred.MapTask: Processing split: Paths:/tmp/beetest/warehouse/beetest.db/stream/input.tsv:0+296InputFormatClass: org.apache.hadoop.mapred.TextInputFormat

20/07/30 21:43:20 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/map.xml
20/07/30 21:43:20 INFO exec.Utilities: local path = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/map.xml
20/07/30 21:43:20 INFO exec.Utilities: Open file to read in plan: file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/map.xml
20/07/30 21:43:20 INFO log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:20 INFO exec.Utilities: Deserializing MapWork via kryo
20/07/30 21:43:20 INFO log.PerfLogger: </PERFLOG method=deserializePlan start=1596145400443 end=1596145400500 duration=57 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:20 INFO io.HiveContextAwareRecordReader: Processing file hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/stream/input.tsv
20/07/30 21:43:20 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file
20/07/30 21:43:20 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start
20/07/30 21:43:20 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length
20/07/30 21:43:20 INFO mapred.MapTask: numReduceTasks: 1
20/07/30 21:43:20 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/07/30 21:43:20 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/07/30 21:43:20 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/07/30 21:43:20 INFO mapred.MapTask: soft limit at 83886080
20/07/30 21:43:20 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/07/30 21:43:20 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/07/30 21:43:20 INFO mr.ExecMapper: conf classpath = [file:/tmp/tmpu74hqnl2/Beetest/target/surefire/surefirebooter4132999497326036676.jar, file:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar]
20/07/30 21:43:20 INFO mr.ExecMapper: thread classpath = [file:/tmp/tmpu74hqnl2/Beetest/target/surefire/surefirebooter4132999497326036676.jar, file:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar]
20/07/30 21:43:20 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/map.xml
20/07/30 21:43:20 INFO exec.MapOperator: Initializing operator MAP[16]
20/07/30 21:43:20 INFO exec.MapOperator: Initialization Done 16 MAP
20/07/30 21:43:20 INFO exec.MapOperator: Operator 16 MAP initialized
20/07/30 21:43:21 INFO mr.ExecMapper: 
<MAP>Id =16
  <Children>
    <TS>Id =12
      <Children>
        <SEL>Id =13
          <Children>
            <GBY>Id =14
              <Children>
                <RS>Id =15
                  <Children>
                  <\Children>
                  <Parent>Id = 14 null<\Parent>
                <\RS>
              <\Children>
              <Parent>Id = 13 null<\Parent>
            <\GBY>
          <\Children>
          <Parent>Id = 12 null<\Parent>
        <\SEL>
      <\Children>
      <Parent>Id = 16 null<\Parent>
    <\TS>
  <\Children>
  <Parent><\Parent>
<\MAP>
20/07/30 21:43:21 INFO MapredContext: MapredContext initialized.
20/07/30 21:43:21 INFO exec.TableScanOperator: Initializing operator TS[12]
20/07/30 21:43:21 INFO exec.TableScanOperator: Initialization Done 12 TS
20/07/30 21:43:21 INFO exec.TableScanOperator: Operator 12 TS initialized
20/07/30 21:43:21 INFO exec.TableScanOperator: Initializing children of 12 TS
20/07/30 21:43:21 INFO exec.SelectOperator: Initializing child 13 SEL
20/07/30 21:43:21 INFO exec.SelectOperator: Initializing operator SEL[13]
20/07/30 21:43:21 INFO exec.SelectOperator: SELECT struct<artist:string,song:string,user:string,ts:timestamp>
20/07/30 21:43:21 INFO exec.SelectOperator: Initialization Done 13 SEL
20/07/30 21:43:21 INFO exec.SelectOperator: Operator 13 SEL initialized
20/07/30 21:43:21 INFO exec.SelectOperator: Initializing children of 13 SEL
20/07/30 21:43:21 INFO exec.GroupByOperator: Initializing child 14 GBY
20/07/30 21:43:21 INFO exec.GroupByOperator: Initializing operator GBY[14]
20/07/30 21:43:21 INFO exec.GroupByOperator: Initialization Done 14 GBY
20/07/30 21:43:21 INFO exec.GroupByOperator: Operator 14 GBY initialized
20/07/30 21:43:21 INFO exec.GroupByOperator: Initializing children of 14 GBY
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: Initializing child 15 RS
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: Initializing operator RS[15]
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: Using tag = -1
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: Initialization Done 15 RS
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: Operator 15 RS initialized
20/07/30 21:43:21 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/map.xml
20/07/30 21:43:21 INFO DataNode.clienttrace: src: /127.0.0.1:33509, dest: /127.0.0.1:56348, bytes: 300, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1177678987_1, offset: 0, srvID: DS-1159781685-172.17.0.16-33509-1596145383549, blockid: BP-2050360059-172.17.0.16-1596145382623:blk_1073741825_1001, duration: 1277755
20/07/30 21:43:21 INFO exec.MapOperator: MAP[16]: records read - 1
20/07/30 21:43:21 INFO exec.MapOperator: 16 finished. closing... 
20/07/30 21:43:21 INFO exec.MapOperator: DESERIALIZE_ERRORS:0
20/07/30 21:43:21 INFO exec.MapOperator: RECORDS_IN:6
20/07/30 21:43:21 INFO exec.TableScanOperator: 12 finished. closing... 
20/07/30 21:43:21 INFO exec.SelectOperator: 13 finished. closing... 
20/07/30 21:43:21 INFO exec.GroupByOperator: 14 finished. closing... 
20/07/30 21:43:21 INFO exec.GroupByOperator: Begin Hash Table flush: size = 3
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: keys are [_col0] num distributions: 1
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: RS[15]: records written - 1
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: 15 finished. closing... 
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: RS[15]: records written - 3
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3
20/07/30 21:43:21 INFO exec.ReduceSinkOperator: 15 Close done
20/07/30 21:43:21 INFO exec.GroupByOperator: 14 Close done
20/07/30 21:43:21 INFO exec.SelectOperator: 13 Close done
20/07/30 21:43:21 INFO exec.TableScanOperator: 12 Close done
20/07/30 21:43:21 INFO exec.MapOperator: 16 Close done
20/07/30 21:43:21 INFO mapred.LocalJobRunner: 
20/07/30 21:43:21 INFO mapred.MapTask: Starting flush of map output
20/07/30 21:43:21 INFO mapred.MapTask: Spilling map output
20/07/30 21:43:21 INFO mapred.MapTask: bufstart = 0; bufend = 61; bufvoid = 104857600
20/07/30 21:43:21 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
20/07/30 21:43:21 INFO mapred.MapTask: Finished spill 0
20/07/30 21:43:21 INFO mapred.Task: Task:attempt_local1487730247_0001_m_000000_0 is done. And is in the process of committing
2020-07-30 21:43:21,351 Stage-1 map = 0%,  reduce = 0%
20/07/30 21:43:21 INFO exec.Task: 2020-07-30 21:43:21,351 Stage-1 map = 0%,  reduce = 0%
20/07/30 21:43:21 INFO mapred.LocalJobRunner: hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/stream/input.tsv:0+296
20/07/30 21:43:21 INFO mapred.Task: Task 'attempt_local1487730247_0001_m_000000_0' done.
20/07/30 21:43:21 INFO mapred.LocalJobRunner: Finishing task: attempt_local1487730247_0001_m_000000_0
20/07/30 21:43:21 INFO mapred.LocalJobRunner: Map task executor complete.
20/07/30 21:43:21 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/07/30 21:43:21 INFO mapred.Merger: Merging 1 sorted segments
20/07/30 21:43:21 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 51 bytes
20/07/30 21:43:21 INFO mapred.LocalJobRunner: 
20/07/30 21:43:21 INFO ExecReducer: conf classpath = [file:/tmp/tmpu74hqnl2/Beetest/target/surefire/surefirebooter4132999497326036676.jar, file:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar]
20/07/30 21:43:21 INFO ExecReducer: thread classpath = [file:/tmp/tmpu74hqnl2/Beetest/target/surefire/surefirebooter4132999497326036676.jar, file:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar]
20/07/30 21:43:21 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/reduce.xml
20/07/30 21:43:21 INFO exec.Utilities: local path = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/reduce.xml
20/07/30 21:43:21 INFO exec.Utilities: Open file to read in plan: file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-2/-mr-10005/57e17c05-0a95-4119-8101-15f8fab57af5/reduce.xml
20/07/30 21:43:21 INFO log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:21 INFO exec.Utilities: Deserializing ReduceWork via kryo
20/07/30 21:43:21 INFO log.PerfLogger: </PERFLOG method=deserializePlan start=1596145401386 end=1596145401409 duration=23 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:21 INFO MapredContext: MapredContext initialized.
20/07/30 21:43:21 INFO ExecReducer: 
<GBY>Id =17
  <Children>
    <FS>Id =18
      <Children>
      <\Children>
      <Parent>Id = 17 null<\Parent>
    <\FS>
  <\Children>
  <Parent><\Parent>
<\GBY>
20/07/30 21:43:21 INFO exec.GroupByOperator: Initializing operator GBY[17]
20/07/30 21:43:21 INFO exec.GroupByOperator: Initialization Done 17 GBY
20/07/30 21:43:21 INFO exec.GroupByOperator: Operator 17 GBY initialized
20/07/30 21:43:21 INFO exec.GroupByOperator: Initializing children of 17 GBY
20/07/30 21:43:21 INFO exec.FileSinkOperator: Initializing child 18 FS
20/07/30 21:43:21 INFO exec.FileSinkOperator: Initializing operator FS[18]
20/07/30 21:43:21 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
20/07/30 21:43:21 INFO exec.FileSinkOperator: Using serializer : org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe@78dc49c4 and formatter : org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat@6762c2f4
20/07/30 21:43:21 INFO Configuration.deprecation: mapred.healthChecker.script.timeout is deprecated. Instead, use mapreduce.tasktracker.healthchecker.script.timeout
20/07/30 21:43:21 INFO exec.FileSinkOperator: Initialization Done 18 FS
20/07/30 21:43:21 INFO exec.FileSinkOperator: Operator 18 FS initialized
20/07/30 21:43:21 INFO exec.FileSinkOperator: Final Path: FS file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/_tmp.-mr-10003/000000_0
20/07/30 21:43:21 INFO exec.FileSinkOperator: Writing to temp file: FS file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/_task_tmp.-mr-10003/_tmp.000000_0
20/07/30 21:43:21 INFO exec.FileSinkOperator: New Final Path: FS file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/_tmp.-mr-10003/000000_0
20/07/30 21:43:21 INFO exec.FileSinkOperator: FS[18]: records written - 1
20/07/30 21:43:21 INFO exec.GroupByOperator: 17 finished. closing... 
20/07/30 21:43:21 INFO exec.FileSinkOperator: 18 finished. closing... 
20/07/30 21:43:21 INFO exec.FileSinkOperator: FS[18]: records written - 3
20/07/30 21:43:21 INFO exec.FileSinkOperator: RECORDS_OUT_0:3
20/07/30 21:43:21 INFO exec.FileSinkOperator: 18 Close done
20/07/30 21:43:21 INFO exec.GroupByOperator: 17 Close done
20/07/30 21:43:21 INFO mapred.Task: Task:attempt_local1487730247_0001_r_000000_0 is done. And is in the process of committing
20/07/30 21:43:21 INFO mapred.LocalJobRunner: reduce > reduce
20/07/30 21:43:21 INFO mapred.Task: Task 'attempt_local1487730247_0001_r_000000_0' done.
2020-07-30 21:43:22,373 Stage-1 map = 100%,  reduce = 100%
20/07/30 21:43:22 INFO exec.Task: 2020-07-30 21:43:22,373 Stage-1 map = 100%,  reduce = 100%
Ended Job = job_local1487730247_0001
20/07/30 21:43:22 INFO exec.Task: Ended Job = job_local1487730247_0001
20/07/30 21:43:22 INFO exec.FileSinkOperator: Moving tmp dir: file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/_tmp.-mr-10003 to: file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003
20/07/30 21:43:23 INFO log.PerfLogger: <PERFLOG method=task.MAPRED.Stage-2 from=org.apache.hadoop.hive.ql.Driver>
Launching Job 2 out of 2
20/07/30 21:43:23 INFO ql.Driver: Launching Job 2 out of 2
20/07/30 21:43:23 INFO ql.Driver: Starting task [Stage-2:MAPRED] in parallel
Number of reduce tasks determined at compile time: 1
20/07/30 21:43:23 INFO exec.Task: Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
20/07/30 21:43:23 INFO exec.Task: In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
20/07/30 21:43:23 INFO exec.Task:   set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
20/07/30 21:43:23 INFO exec.Task: In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
20/07/30 21:43:23 INFO exec.Task:   set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
20/07/30 21:43:23 INFO exec.Task: In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
20/07/30 21:43:23 INFO exec.Task:   set mapreduce.job.reduces=<number>
20/07/30 21:43:23 INFO mr.ExecDriver: Using org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
20/07/30 21:43:23 INFO exec.Utilities: Processing alias file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003
20/07/30 21:43:23 INFO exec.Utilities: Adding input file file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003
20/07/30 21:43:23 INFO exec.Utilities: Content Summary not cached for file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003
20/07/30 21:43:23 INFO log.PerfLogger: <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:23 INFO exec.Utilities: Serializing MapWork via kryo
20/07/30 21:43:23 INFO log.PerfLogger: </PERFLOG method=serializePlan start=1596145403533 end=1596145403540 duration=7 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:23 INFO log.PerfLogger: <PERFLOG method=serializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:23 INFO exec.Utilities: Serializing ReduceWork via kryo
20/07/30 21:43:23 INFO log.PerfLogger: </PERFLOG method=serializePlan start=1596145403545 end=1596145403549 duration=4 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:23 ERROR mr.ExecDriver: local
20/07/30 21:43:23 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
20/07/30 21:43:23 INFO fs.FSStatsPublisher: created : hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10002
20/07/30 21:43:23 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
20/07/30 21:43:23 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/map.xml
20/07/30 21:43:23 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/reduce.xml
20/07/30 21:43:23 WARN mapreduce.JobSubmitter: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
20/07/30 21:43:23 INFO log.PerfLogger: <PERFLOG method=getSplits from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
20/07/30 21:43:23 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/map.xml
20/07/30 21:43:23 INFO io.CombineHiveInputFormat: Total number of paths: 1, launching 1 threads to check non-combinable ones.
20/07/30 21:43:23 INFO io.CombineHiveInputFormat: CombineHiveInputSplit creating pool for file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003; using filter path file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003
20/07/30 21:43:23 INFO input.FileInputFormat: Total input paths to process : 1
20/07/30 21:43:23 INFO input.CombineFileInputFormat: DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 0
20/07/30 21:43:23 INFO io.CombineHiveInputFormat: number of splits 1
20/07/30 21:43:23 INFO io.CombineHiveInputFormat: Number of all splits 1
20/07/30 21:43:23 INFO log.PerfLogger: </PERFLOG method=getSplits start=1596145403670 end=1596145403683 duration=13 from=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat>
20/07/30 21:43:23 INFO mapreduce.JobSubmitter: number of splits:1
20/07/30 21:43:23 INFO Configuration.deprecation: topology.node.switch.mapping.impl is deprecated. Instead, use net.topology.node.switch.mapping.impl
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
20/07/30 21:43:23 INFO Configuration.deprecation: dfs.safemode.extension is deprecated. Instead, use dfs.namenode.safemode.extension
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.reduce.tasks.speculative.execution is deprecated. Instead, use mapreduce.reduce.speculative
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.committer.job.setup.cleanup.needed is deprecated. Instead, use mapreduce.job.committer.setup.cleanup.needed
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.jar is deprecated. Instead, use mapreduce.job.jar
20/07/30 21:43:23 INFO Configuration.deprecation: dfs.http.address is deprecated. Instead, use dfs.namenode.http-address
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.mapoutput.value.class is deprecated. Instead, use mapreduce.map.output.value.class
20/07/30 21:43:23 INFO Configuration.deprecation: slave.host.name is deprecated. Instead, use dfs.datanode.hostname
20/07/30 21:43:23 INFO Configuration.deprecation: dfs.umaskmode is deprecated. Instead, use fs.permissions.umask-mode
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.job.name is deprecated. Instead, use mapreduce.job.name
20/07/30 21:43:23 INFO Configuration.deprecation: dfs.permissions is deprecated. Instead, use dfs.permissions.enabled
20/07/30 21:43:23 INFO Configuration.deprecation: dfs.name.dir is deprecated. Instead, use dfs.namenode.name.dir
20/07/30 21:43:23 INFO Configuration.deprecation: dfs.data.dir is deprecated. Instead, use dfs.datanode.data.dir
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.mapoutput.key.class is deprecated. Instead, use mapreduce.map.output.key.class
20/07/30 21:43:23 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name
20/07/30 21:43:23 INFO Configuration.deprecation: fs.checkpoint.dir is deprecated. Instead, use dfs.namenode.checkpoint.dir
20/07/30 21:43:23 INFO Configuration.deprecation: fs.default.name is deprecated. Instead, use fs.defaultFS
20/07/30 21:43:23 INFO Configuration.deprecation: mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
20/07/30 21:43:23 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1643573475_0002
20/07/30 21:43:23 WARN conf.Configuration: file:/tmp/hadoop-jdbl/mapred/staging/jdbl1643573475/.staging/job_local1643573475_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
20/07/30 21:43:23 WARN conf.Configuration: file:/tmp/hadoop-jdbl/mapred/staging/jdbl1643573475/.staging/job_local1643573475_0002/job.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
20/07/30 21:43:23 WARN conf.Configuration: file:/tmp/hadoop-jdbl/mapred/local/localRunner/jdbl/job_local1643573475_0002/job_local1643573475_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.retry.interval;  Ignoring.
20/07/30 21:43:23 WARN conf.Configuration: file:/tmp/hadoop-jdbl/mapred/local/localRunner/jdbl/job_local1643573475_0002/job_local1643573475_0002.xml:an attempt to override final parameter: mapreduce.job.end-notification.max.attempts;  Ignoring.
20/07/30 21:43:23 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
Job running in-process (local Hadoop)
20/07/30 21:43:23 INFO exec.Task: Job running in-process (local Hadoop)
20/07/30 21:43:23 INFO mapred.LocalJobRunner: OutputCommitter set in config org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
20/07/30 21:43:23 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.hive.ql.io.HiveFileFormatUtils$NullOutputCommitter
20/07/30 21:43:23 INFO mapred.LocalJobRunner: Waiting for map tasks
20/07/30 21:43:23 INFO mapred.LocalJobRunner: Starting task: attempt_local1643573475_0002_m_000000_0
20/07/30 21:43:23 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/07/30 21:43:23 INFO mapred.MapTask: Processing split: Paths:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003/000000_0:0+175InputFormatClass: org.apache.hadoop.mapred.SequenceFileInputFormat

20/07/30 21:43:23 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/map.xml
20/07/30 21:43:23 INFO exec.Utilities: local path = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/map.xml
20/07/30 21:43:23 INFO exec.Utilities: Open file to read in plan: file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/map.xml
20/07/30 21:43:23 INFO log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:23 INFO exec.Utilities: Deserializing MapWork via kryo
20/07/30 21:43:23 INFO log.PerfLogger: </PERFLOG method=deserializePlan start=1596145403920 end=1596145403924 duration=4 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:23 INFO io.HiveContextAwareRecordReader: Processing file file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003/000000_0
20/07/30 21:43:23 INFO mapred.MapTask: numReduceTasks: 1
20/07/30 21:43:23 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
20/07/30 21:43:23 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
20/07/30 21:43:23 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
20/07/30 21:43:23 INFO mapred.MapTask: soft limit at 83886080
20/07/30 21:43:23 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
20/07/30 21:43:23 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
20/07/30 21:43:23 INFO mr.ExecMapper: conf classpath = [file:/tmp/tmpu74hqnl2/Beetest/target/surefire/surefirebooter4132999497326036676.jar, file:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar]
20/07/30 21:43:23 INFO mr.ExecMapper: thread classpath = [file:/tmp/tmpu74hqnl2/Beetest/target/surefire/surefirebooter4132999497326036676.jar, file:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar]
20/07/30 21:43:23 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/map.xml
20/07/30 21:43:23 INFO exec.MapOperator: Initializing operator MAP[25]
20/07/30 21:43:23 INFO exec.MapOperator: Initialization Done 25 MAP
20/07/30 21:43:23 INFO exec.MapOperator: Operator 25 MAP initialized
20/07/30 21:43:23 INFO mr.ExecMapper: 
<MAP>Id =25
  <Children>
    <TS>Id =23
      <Children>
        <RS>Id =24
          <Children>
          <\Children>
          <Parent>Id = 23 null<\Parent>
        <\RS>
      <\Children>
      <Parent>Id = 25 null<\Parent>
    <\TS>
  <\Children>
  <Parent><\Parent>
<\MAP>
20/07/30 21:43:23 INFO MapredContext: MapredContext initialized.
20/07/30 21:43:23 INFO exec.TableScanOperator: Initializing operator TS[23]
20/07/30 21:43:23 INFO exec.TableScanOperator: Initialization Done 23 TS
20/07/30 21:43:23 INFO exec.TableScanOperator: Operator 23 TS initialized
20/07/30 21:43:23 INFO exec.TableScanOperator: Initializing children of 23 TS
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: Initializing child 24 RS
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: Initializing operator RS[24]
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: Using tag = -1
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: Initialization Done 24 RS
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: Operator 24 RS initialized
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: keys are [reducesinkkey0] num distributions: 1
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: RS[24]: records written - 1
20/07/30 21:43:23 INFO exec.MapOperator: MAP[25]: records read - 1
20/07/30 21:43:23 INFO exec.MapOperator: 25 finished. closing... 
20/07/30 21:43:23 INFO exec.MapOperator: DESERIALIZE_ERRORS:0
20/07/30 21:43:23 INFO exec.MapOperator: RECORDS_IN:3
20/07/30 21:43:23 INFO exec.TableScanOperator: 23 finished. closing... 
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: 24 finished. closing... 
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: RS[24]: records written - 3
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: RECORDS_OUT_INTERMEDIATE:3
20/07/30 21:43:23 INFO exec.ReduceSinkOperator: 24 Close done
20/07/30 21:43:23 INFO exec.TableScanOperator: 23 Close done
20/07/30 21:43:23 INFO exec.MapOperator: 25 Close done
20/07/30 21:43:23 INFO mapred.LocalJobRunner: 
20/07/30 21:43:23 INFO mapred.MapTask: Starting flush of map output
20/07/30 21:43:23 INFO mapred.MapTask: Spilling map output
20/07/30 21:43:23 INFO mapred.MapTask: bufstart = 0; bufend = 82; bufvoid = 104857600
20/07/30 21:43:23 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
20/07/30 21:43:23 INFO mapred.MapTask: Finished spill 0
20/07/30 21:43:23 INFO mapred.Task: Task:attempt_local1643573475_0002_m_000000_0 is done. And is in the process of committing
20/07/30 21:43:23 INFO mapred.LocalJobRunner: file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-1/-mr-10003/000000_0:0+175
20/07/30 21:43:23 INFO mapred.Task: Task 'attempt_local1643573475_0002_m_000000_0' done.
20/07/30 21:43:23 INFO mapred.LocalJobRunner: Finishing task: attempt_local1643573475_0002_m_000000_0
20/07/30 21:43:23 INFO mapred.LocalJobRunner: Map task executor complete.
20/07/30 21:43:23 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/07/30 21:43:23 INFO mapred.Merger: Merging 1 sorted segments
20/07/30 21:43:23 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 74 bytes
20/07/30 21:43:23 INFO mapred.LocalJobRunner: 
20/07/30 21:43:23 INFO ExecReducer: conf classpath = [file:/tmp/tmpu74hqnl2/Beetest/target/surefire/surefirebooter4132999497326036676.jar, file:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar]
20/07/30 21:43:23 INFO ExecReducer: thread classpath = [file:/tmp/tmpu74hqnl2/Beetest/target/surefire/surefirebooter4132999497326036676.jar, file:/home/jdbl/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar]
20/07/30 21:43:23 INFO exec.Utilities: PLAN PATH = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/reduce.xml
20/07/30 21:43:23 INFO exec.Utilities: local path = file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/reduce.xml
20/07/30 21:43:23 INFO exec.Utilities: Open file to read in plan: file:/tmp/beetest-test-705574401/localScratchDir/b08c0b59-44da-42df-b8af-01c839cfc621/hive_2020-07-30_21-43-18_938_6652828740336882048-3/-mr-10007/63202892-5f1a-4655-9255-e65120e54a95/reduce.xml
20/07/30 21:43:23 INFO log.PerfLogger: <PERFLOG method=deserializePlan from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:23 INFO exec.Utilities: Deserializing ReduceWork via kryo
20/07/30 21:43:24 INFO log.PerfLogger: </PERFLOG method=deserializePlan start=1596145403993 end=1596145404004 duration=11 from=org.apache.hadoop.hive.ql.exec.Utilities>
20/07/30 21:43:24 INFO MapredContext: MapredContext initialized.
20/07/30 21:43:24 INFO ExecReducer: 
<SEL>Id =26
  <Children>
    <LIM>Id =27
      <Children>
        <FS>Id =28
          <Children>
          <\Children>
          <Parent>Id = 27 null<\Parent>
        <\FS>
      <\Children>
      <Parent>Id = 26 null<\Parent>
    <\LIM>
  <\Children>
  <Parent><\Parent>
<\SEL>
20/07/30 21:43:24 INFO exec.SelectOperator: Initializing operator SEL[26]
20/07/30 21:43:24 INFO exec.SelectOperator: SELECT struct<key:struct<reducesinkkey0:bigint>,value:struct<_col0:string>>
20/07/30 21:43:24 INFO exec.SelectOperator: Initialization Done 26 SEL
20/07/30 21:43:24 INFO exec.SelectOperator: Operator 26 SEL initialized
20/07/30 21:43:24 INFO exec.SelectOperator: Initializing children of 26 SEL
20/07/30 21:43:24 INFO exec.LimitOperator: Initializing child 27 LIM
20/07/30 21:43:24 INFO exec.LimitOperator: Initializing operator LIM[27]
20/07/30 21:43:24 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
20/07/30 21:43:24 INFO exec.LimitOperator: Initialization Done 27 LIM
20/07/30 21:43:24 INFO exec.LimitOperator: Operator 27 LIM initialized
20/07/30 21:43:24 INFO exec.LimitOperator: Initializing children of 27 LIM
20/07/30 21:43:24 INFO exec.FileSinkOperator: Initializing child 28 FS
20/07/30 21:43:24 INFO exec.FileSinkOperator: Initializing operator FS[28]
20/07/30 21:43:24 INFO exec.FileSinkOperator: Using serializer : class org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe[[[B@778ad6b2]:[artist, cnt]:[string, bigint]] and formatter : org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat@d65e266
20/07/30 21:43:24 INFO exec.FileSinkOperator: Initialization Done 28 FS
20/07/30 21:43:24 INFO exec.FileSinkOperator: Operator 28 FS initialized
20/07/30 21:43:24 INFO exec.FileSinkOperator: Final Path: FS hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/_tmp.-ext-10001/000000_0
20/07/30 21:43:24 INFO exec.FileSinkOperator: Writing to temp file: FS hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/_task_tmp.-ext-10001/_tmp.000000_0
20/07/30 21:43:24 INFO exec.FileSinkOperator: New Final Path: FS hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/_tmp.-ext-10001/000000_0
20/07/30 21:43:24 INFO exec.FileSinkOperator: FS[28]: records written - 1
20/07/30 21:43:24 INFO exec.SelectOperator: 26 finished. closing... 
20/07/30 21:43:24 INFO exec.LimitOperator: 27 finished. closing... 
20/07/30 21:43:24 INFO exec.FileSinkOperator: 28 finished. closing... 
20/07/30 21:43:24 INFO exec.FileSinkOperator: FS[28]: records written - 2
20/07/30 21:43:24 INFO hdfs.StateChange: BLOCK* allocateBlock: /tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/_task_tmp.-ext-10001/_tmp.000000_0. BP-2050360059-172.17.0.16-1596145382623 blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:33509|RBW]]}
20/07/30 21:43:24 INFO datanode.DataNode: Receiving BP-2050360059-172.17.0.16-1596145382623:blk_1073741826_1002 src: /127.0.0.1:56502 dest: /127.0.0.1:33509
20/07/30 21:43:24 INFO DataNode.clienttrace: src: /127.0.0.1:56502, dest: /127.0.0.1:33509, bytes: 19, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1177678987_1, offset: 0, srvID: DS-1159781685-172.17.0.16-33509-1596145383549, blockid: BP-2050360059-172.17.0.16-1596145382623:blk_1073741826_1002, duration: 4453608
20/07/30 21:43:24 INFO datanode.DataNode: PacketResponder: BP-2050360059-172.17.0.16-1596145382623:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
20/07/30 21:43:24 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33509 is added to blk_1073741826_1002{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:33509|RBW]]} size 0
20/07/30 21:43:24 INFO hdfs.StateChange: DIR* completeFile: /tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/_task_tmp.-ext-10001/_tmp.000000_0 is closed by DFSClient_NONMAPREDUCE_1177678987_1
20/07/30 21:43:24 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
20/07/30 21:43:24 INFO fs.FSStatsPublisher: Created file : hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10002/tmpstats-0
20/07/30 21:43:24 INFO fs.FSStatsPublisher: Writing stats in it : {beetest.output_705574401/={rawDataSize=17, numRows=2}}
20/07/30 21:43:24 INFO hdfs.StateChange: BLOCK* allocateBlock: /tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10002/tmpstats-0. BP-2050360059-172.17.0.16-1596145382623 blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:33509|RBW]]}
20/07/30 21:43:24 INFO datanode.DataNode: Receiving BP-2050360059-172.17.0.16-1596145382623:blk_1073741827_1003 src: /127.0.0.1:56506 dest: /127.0.0.1:33509
20/07/30 21:43:24 INFO DataNode.clienttrace: src: /127.0.0.1:56506, dest: /127.0.0.1:33509, bytes: 80, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1177678987_1, offset: 0, srvID: DS-1159781685-172.17.0.16-33509-1596145383549, blockid: BP-2050360059-172.17.0.16-1596145382623:blk_1073741827_1003, duration: 1235595
20/07/30 21:43:24 INFO datanode.DataNode: PacketResponder: BP-2050360059-172.17.0.16-1596145382623:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
20/07/30 21:43:24 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 127.0.0.1:33509 is added to blk_1073741827_1003{blockUCState=UNDER_CONSTRUCTION, primaryNodeIndex=-1, replicas=[ReplicaUnderConstruction[127.0.0.1:33509|RBW]]} size 0
20/07/30 21:43:24 INFO hdfs.StateChange: DIR* completeFile: /tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10002/tmpstats-0 is closed by DFSClient_NONMAPREDUCE_1177678987_1
20/07/30 21:43:24 INFO exec.FileSinkOperator: RECORDS_OUT_1_beetest.output_705574401:2
20/07/30 21:43:24 INFO exec.FileSinkOperator: 28 Close done
20/07/30 21:43:24 INFO exec.LimitOperator: 27 Close done
20/07/30 21:43:24 INFO exec.SelectOperator: 26 Close done
20/07/30 21:43:24 INFO mapred.Task: Task:attempt_local1643573475_0002_r_000000_0 is done. And is in the process of committing
20/07/30 21:43:24 INFO mapred.LocalJobRunner: reduce > reduce
20/07/30 21:43:24 INFO mapred.Task: Task 'attempt_local1643573475_0002_r_000000_0' done.
2020-07-30 21:43:24,899 Stage-2 map = 100%,  reduce = 100%
20/07/30 21:43:24 INFO exec.Task: 2020-07-30 21:43:24,899 Stage-2 map = 100%,  reduce = 100%
Ended Job = job_local1643573475_0002
20/07/30 21:43:24 INFO exec.Task: Ended Job = job_local1643573475_0002
20/07/30 21:43:24 INFO exec.FileSinkOperator: Moving tmp dir: hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/_tmp.-ext-10001 to: hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10001
20/07/30 21:43:27 INFO log.PerfLogger: <PERFLOG method=task.MOVE.Stage-0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:27 INFO ql.Driver: Starting task [Stage-0:MOVE] in serial mode
Moving data to: /tmp/beetest-test-705574401-output_705574401
20/07/30 21:43:27 INFO exec.Task: Moving data to: /tmp/beetest-test-705574401-output_705574401 from hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10001
20/07/30 21:43:27 INFO metadata.Hive: Replacing src:hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10001, dest: /tmp/beetest-test-705574401-output_705574401, Status:true
20/07/30 21:43:27 INFO log.PerfLogger: <PERFLOG method=task.DDL.Stage-4 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:27 INFO ql.Driver: Starting task [Stage-4:DDL] in serial mode
20/07/30 21:43:27 INFO metastore.HiveMetaStore: 0: create_table: Table(tableName:output_705574401, dbName:beetest, owner:jdbl, createTime:1596145407, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:artist, type:string, comment:null), FieldSchema(name:cnt, type:bigint, comment:null)], location:hdfs://localhost:43831/tmp/beetest-test-705574401-output_705574401, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{field.delim=	, colelction.delim=|, mapkey.delim=$, serialization.format=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)
20/07/30 21:43:27 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=create_table: Table(tableName:output_705574401, dbName:beetest, owner:jdbl, createTime:1596145407, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:artist, type:string, comment:null), FieldSchema(name:cnt, type:bigint, comment:null)], location:hdfs://localhost:43831/tmp/beetest-test-705574401-output_705574401, inputFormat:org.apache.hadoop.mapred.TextInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, parameters:{field.delim=	, colelction.delim=|, mapkey.delim=$, serialization.format=	}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[], parameters:{}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{}, groupPrivileges:null, rolePrivileges:null), temporary:false)	
20/07/30 21:43:27 WARN metastore.HiveMetaStore: Location: hdfs://localhost:43831/tmp/beetest-test-705574401-output_705574401 specified for non-external table:output_705574401
20/07/30 21:43:27 INFO hive.log: Updating table stats fast for output_705574401
20/07/30 21:43:27 INFO hive.log: Updated size of table output_705574401 to 0
20/07/30 21:43:27 INFO log.PerfLogger: <PERFLOG method=task.STATS.Stage-3 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:27 INFO ql.Driver: Starting task [Stage-3:STATS] in serial mode
20/07/30 21:43:27 INFO exec.StatsTask: Executing stats task
20/07/30 21:43:27 INFO metastore.HiveMetaStore: 0: get_table : db=beetest tbl=output_705574401
20/07/30 21:43:27 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=get_table : db=beetest tbl=output_705574401	
20/07/30 21:43:27 INFO fs.FSStatsPublisher: created : hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/-ext-10002
20/07/30 21:43:27 INFO DataNode.clienttrace: src: /127.0.0.1:33509, dest: /127.0.0.1:56676, bytes: 84, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1177678987_1, offset: 0, srvID: DS-1159781685-172.17.0.16-33509-1596145383549, blockid: BP-2050360059-172.17.0.16-1596145382623:blk_1073741827_1003, duration: 3600283
20/07/30 21:43:27 INFO fs.FSStatsAggregator: Read stats : {beetest.output_705574401/={rawDataSize=17, numRows=2}}
20/07/30 21:43:27 INFO fs.FSStatsAggregator: Read stats for : beetest.output_705574401/	numRows	2
20/07/30 21:43:27 INFO fs.FSStatsAggregator: Read stats for : beetest.output_705574401/	rawDataSize	17
20/07/30 21:43:27 INFO metastore.HiveMetaStore: 0: alter_table: db=beetest tbl=output_705574401 newtbl=output_705574401
20/07/30 21:43:27 INFO HiveMetaStore.audit: ugi=jdbl	ip=unknown-ip-addr	cmd=alter_table: db=beetest tbl=output_705574401 newtbl=output_705574401	
20/07/30 21:43:27 INFO hive.log: Updating table stats fast for output_705574401
20/07/30 21:43:27 INFO hive.log: Updated size of table output_705574401 to 0
Table beetest.output_705574401 stats: [numFiles=0, numRows=2, totalSize=0, rawDataSize=17]
20/07/30 21:43:27 INFO exec.Task: Table beetest.output_705574401 stats: [numFiles=0, numRows=2, totalSize=0, rawDataSize=17]
20/07/30 21:43:27 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741827_1003 127.0.0.1:33509 
20/07/30 21:43:27 INFO log.PerfLogger: </PERFLOG method=runTasks start=1596145399450 end=1596145407721 duration=8271 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:27 INFO log.PerfLogger: </PERFLOG method=Driver.execute start=1596145399449 end=1596145407721 duration=8272 from=org.apache.hadoop.hive.ql.Driver>
MapReduce Jobs Launched: 
20/07/30 21:43:27 INFO ql.Driver: MapReduce Jobs Launched: 
Stage-Stage-1:  HDFS Read: 592 HDFS Write: 592 SUCCESS
20/07/30 21:43:27 INFO ql.Driver: Stage-Stage-1:  HDFS Read: 592 HDFS Write: 592 SUCCESS
Stage-Stage-2:  HDFS Read: 592 HDFS Write: 691 SUCCESS
20/07/30 21:43:27 INFO ql.Driver: Stage-Stage-2:  HDFS Read: 592 HDFS Write: 691 SUCCESS
Total MapReduce CPU Time Spent: 0 msec
20/07/30 21:43:27 INFO ql.Driver: Total MapReduce CPU Time Spent: 0 msec
OK
20/07/30 21:43:27 INFO ql.Driver: OK
20/07/30 21:43:27 INFO log.PerfLogger: <PERFLOG method=releaseLocks from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:27 INFO log.PerfLogger: </PERFLOG method=releaseLocks start=1596145407725 end=1596145407725 duration=0 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:27 INFO log.PerfLogger: </PERFLOG method=Driver.run start=1596145398938 end=1596145407725 duration=8787 from=org.apache.hadoop.hive.ql.Driver>
20/07/30 21:43:27 INFO DataNode.clienttrace: src: /127.0.0.1:33509, dest: /127.0.0.1:56676, bytes: 300, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1177678987_1, offset: 0, srvID: DS-1159781685-172.17.0.16-33509-1596145383549, blockid: BP-2050360059-172.17.0.16-1596145382623:blk_1073741825_1001, duration: 189795
20/07/30 21:43:27 INFO DataNode.clienttrace: src: /127.0.0.1:33509, dest: /127.0.0.1:56676, bytes: 23, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1177678987_1, offset: 0, srvID: DS-1159781685-172.17.0.16-33509-1596145383549, blockid: BP-2050360059-172.17.0.16-1596145382623:blk_1073741826_1002, duration: 231917
Jul 30, 2020 9:43:27 PM com.spotify.beetest.TestQueryExecutor run
INFO: Asserting: /tmp/tmpu74hqnl2/Beetest/src/test/resources/artist-count/expected.txt and /tmp/beetest-test-705574401/outputDirs/000000_0
Jul 30, 2020 9:43:27 PM com.spotify.beetest.TestHiveServer2 tearDown
INFO: STOPPING CLUSTER
20/07/30 21:43:27 INFO hdfs.MiniDFSCluster: Shutting down the Mini HDFS Cluster
20/07/30 21:43:27 INFO hdfs.MiniDFSCluster: Shutting down DataNode 0
20/07/30 21:43:27 WARN datanode.DirectoryScanner: DirectoryScanner: shutdown has been called
20/07/30 21:43:27 INFO mortbay.log: Stopped SelectChannelConnector@localhost:0
20/07/30 21:43:27 INFO ipc.Server: Stopping server on 33475
20/07/30 21:43:27 INFO ipc.Server: Stopping IPC Server listener on 33475
20/07/30 21:43:27 INFO ipc.Server: Stopping IPC Server Responder
20/07/30 21:43:27 INFO datanode.DataNode: Waiting for threadgroup to exit, active threads is 2
20/07/30 21:43:27 INFO datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
20/07/30 21:43:27 WARN datanode.DataNode: BPOfferService for Block pool BP-2050360059-172.17.0.16-1596145382623 (storage id DS-1159781685-172.17.0.16-33509-1596145383549) service to localhost/127.0.0.1:43831 interrupted
20/07/30 21:43:27 WARN datanode.DataNode: Ending block pool service for: Block pool BP-2050360059-172.17.0.16-1596145382623 (storage id DS-1159781685-172.17.0.16-33509-1596145383549) service to localhost/127.0.0.1:43831
20/07/30 21:43:27 INFO datanode.DataNode: Removed Block pool BP-2050360059-172.17.0.16-1596145382623 (storage id DS-1159781685-172.17.0.16-33509-1596145383549)
20/07/30 21:43:27 INFO datanode.DataBlockScanner: Removed bpid=BP-2050360059-172.17.0.16-1596145382623 from blockPoolScannerMap
20/07/30 21:43:27 INFO impl.FsDatasetImpl: Removing block pool BP-2050360059-172.17.0.16-1596145382623
20/07/30 21:43:27 INFO impl.FsDatasetAsyncDiskService: Shutting down all async disk service threads
20/07/30 21:43:27 INFO impl.FsDatasetAsyncDiskService: All async disk service threads have been shut down
20/07/30 21:43:27 INFO namenode.FSNamesystem: Stopping services started for active state
20/07/30 21:43:27 INFO namenode.FSEditLog: Ending log segment 1
20/07/30 21:43:27 INFO namenode.FSEditLog: Number of transactions: 40 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 1 Number of syncs: 30 SyncTimes(ms): 1422 735 
20/07/30 21:43:27 INFO namenode.FileJournalManager: Finalizing edits file /tmp/beetest-test-705574401/BeetestCluster/name1/current/edits_inprogress_0000000000000000001 -> /tmp/beetest-test-705574401/BeetestCluster/name1/current/edits_0000000000000000001-0000000000000000040
20/07/30 21:43:27 INFO namenode.FileJournalManager: Finalizing edits file /tmp/beetest-test-705574401/BeetestCluster/name2/current/edits_inprogress_0000000000000000001 -> /tmp/beetest-test-705574401/BeetestCluster/name2/current/edits_0000000000000000001-0000000000000000040
20/07/30 21:43:27 INFO blockmanagement.BlockManager: Stopping ReplicationMonitor.
20/07/30 21:43:27 WARN blockmanagement.DecommissionManager: Monitor interrupted: java.lang.InterruptedException: sleep interrupted
20/07/30 21:43:27 INFO namenode.FSNamesystem: Stopping services started for active state
20/07/30 21:43:27 INFO namenode.FSNamesystem: Stopping services started for standby state
20/07/30 21:43:27 INFO ipc.Server: Stopping server on 43831
20/07/30 21:43:27 INFO ipc.Server: Stopping IPC Server listener on 43831
20/07/30 21:43:27 INFO ipc.Server: Stopping IPC Server Responder
20/07/30 21:43:27 INFO mortbay.log: Stopped SelectChannelConnector@localhost:0
20/07/30 21:43:27 INFO impl.MetricsSystemImpl: Stopping DataNode metrics system...
20/07/30 21:43:27 INFO impl.MetricsSystemImpl: DataNode metrics system stopped.
20/07/30 21:43:27 INFO impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
20/07/30 21:43:27 INFO server.HiveServer2: Shutting down HiveServer2
20/07/30 21:43:27 INFO thrift.ThriftCLIService: Thrift server has stopped
20/07/30 21:43:27 INFO service.AbstractService: Service:ThriftBinaryCLIService is stopped.
20/07/30 21:43:27 INFO service.AbstractService: Service:OperationManager is stopped.
20/07/30 21:43:27 INFO service.AbstractService: Service:SessionManager is stopped.
20/07/30 21:43:37 INFO service.AbstractService: Service:CLIService is stopped.
20/07/30 21:43:37 INFO service.AbstractService: Service:HiveServer2 is stopped.
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 35.436 sec - in com.spotify.beetest.TestHiveServer2
Running com.spotify.beetest.TestCaseTest
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.007 sec - in com.spotify.beetest.TestCaseTest
Running com.spotify.beetest.UtilsTest
Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.012 sec - in com.spotify.beetest.UtilsTest
20/07/30 21:43:38 INFO server.HiveServer2: Shutting down HiveServer2
20/07/30 21:43:38 INFO server.HiveServer2: Shutting down HiveServer2
20/07/30 21:43:38 INFO server.HiveServer2: Shutting down HiveServer2
20/07/30 21:43:38 INFO server.HiveServer2: Shutting down HiveServer2
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:38933/tmp/beetest/scratchdir/jdbl/104c71fc-4d44-4661-b50c-873e7c2a6eaf
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:38933/tmp/beetest/scratchdir/jdbl/104c71fc-4d44-4661-b50c-873e7c2a6eaf/_tmp_space.db
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:44047/tmp/beetest/scratchdir/jdbl/00269582-130a-44ad-b815-de9967c867f6
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:44047/tmp/beetest/scratchdir/jdbl/00269582-130a-44ad-b815-de9967c867f6/_tmp_space.db
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:43831/tmp/beetest/scratchdir/jdbl/b08c0b59-44da-42df-b8af-01c839cfc621
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:43831/tmp/beetest/scratchdir/jdbl/b08c0b59-44da-42df-b8af-01c839cfc621/_tmp_space.db
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:43831/tmp/beetest/warehouse/beetest.db/.hive-staging_hive_2020-07-30_21-43-18_938_6652828740336882048-1/_task_tmp.-ext-10001/_tmp.000000_0
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:36649/tmp/beetest/scratchdir/jdbl/a5ec7292-f6c5-45d1-8b2b-9ee208a697b1
20/07/30 21:43:38 INFO fs.FileSystem: Ignoring failure to deleteOnExit for path hdfs://localhost:36649/tmp/beetest/scratchdir/jdbl/a5ec7292-f6c5-45d1-8b2b-9ee208a697b1/_tmp_space.db

Results :

Tests run: 12, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- jacoco-maven-plugin:0.8.5:report (report) @ Beetest ---
[INFO] Loading execution data file /tmp/tmpu74hqnl2/Beetest/target/jacoco.exec
[INFO] Analyzed bundle 'Beetest' with 26 classes
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time:  02:35 min
[INFO] Finished at: 2020-07-30T21:43:40Z
[INFO] ------------------------------------------------------------------------
